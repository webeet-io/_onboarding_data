{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üßÆ Data Integration & Schema Design: NYC SAT Results\n",
    "## Comprehensive Data Analysis and Database Integration\n",
    "\n",
    "**Objective**: Evaluate, clean, and integrate NYC SAT Results into existing PostgreSQL schema\n",
    "\n",
    "**Dataset**: `/Users/svitlanakovalivska/onboarding_weebet/_onboarding_data/daily_tasks/day_4/day_4_datasets/sat-results.csv`\n",
    "\n",
    "**Existing Tables**: high_school_directory, school_demographics, school_safety_report\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis Overview\n",
    "This notebook performs comprehensive data cleaning, statistical analysis, and database integration for NYC SAT results data. The analysis follows data science best practices including exploratory data analysis, quality assessment, and systematic data transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Pandas version: 2.3.1\n",
      "NumPy version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import re\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1_header",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "First, let's load the raw SAT results data and examine its structure, identify data quality issues, and understand the dataset characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "data_loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW DATASET OVERVIEW ===\n",
      "Dataset shape: (493, 11)\n",
      "\n",
      "Column names and types:\n",
      "DBN                                 object\n",
      "SCHOOL NAME                         object\n",
      "Num of SAT Test Takers              object\n",
      "SAT Critical Reading Avg. Score     object\n",
      "SAT Math Avg. Score                 object\n",
      "SAT Writing Avg. Score              object\n",
      "SAT Critical Readng Avg. Score      object\n",
      "internal_school_id                   int64\n",
      "contact_extension                   object\n",
      "pct_students_tested                 object\n",
      "academic_tier_rating               float64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>SCHOOL NAME</th>\n",
       "      <th>Num of SAT Test Takers</th>\n",
       "      <th>SAT Critical Reading Avg. Score</th>\n",
       "      <th>SAT Math Avg. Score</th>\n",
       "      <th>SAT Writing Avg. Score</th>\n",
       "      <th>SAT Critical Readng Avg. Score</th>\n",
       "      <th>internal_school_id</th>\n",
       "      <th>contact_extension</th>\n",
       "      <th>pct_students_tested</th>\n",
       "      <th>academic_tier_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>29</td>\n",
       "      <td>355</td>\n",
       "      <td>404</td>\n",
       "      <td>363</td>\n",
       "      <td>355</td>\n",
       "      <td>218160</td>\n",
       "      <td>x345</td>\n",
       "      <td>78%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "      <td>423</td>\n",
       "      <td>366</td>\n",
       "      <td>383</td>\n",
       "      <td>268547</td>\n",
       "      <td>x234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>70</td>\n",
       "      <td>377</td>\n",
       "      <td>402</td>\n",
       "      <td>370</td>\n",
       "      <td>377</td>\n",
       "      <td>236446</td>\n",
       "      <td>x123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>FORSYTH SATELLITE ACADEMY</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>414</td>\n",
       "      <td>427826</td>\n",
       "      <td>x123</td>\n",
       "      <td>92%</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>44</td>\n",
       "      <td>390</td>\n",
       "      <td>433</td>\n",
       "      <td>384</td>\n",
       "      <td>390</td>\n",
       "      <td>672714</td>\n",
       "      <td>x123</td>\n",
       "      <td>92%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DBN                                    SCHOOL NAME  \\\n",
       "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
       "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
       "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
       "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
       "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
       "\n",
       "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
       "0                     29                             355                 404   \n",
       "1                     91                             383                 423   \n",
       "2                     70                             377                 402   \n",
       "3                      7                             414                 401   \n",
       "4                     44                             390                 433   \n",
       "\n",
       "  SAT Writing Avg. Score SAT Critical Readng Avg. Score  internal_school_id  \\\n",
       "0                    363                            355              218160   \n",
       "1                    366                            383              268547   \n",
       "2                    370                            377              236446   \n",
       "3                    359                            414              427826   \n",
       "4                    384                            390              672714   \n",
       "\n",
       "  contact_extension pct_students_tested  academic_tier_rating  \n",
       "0              x345                 78%                   2.0  \n",
       "1              x234                 NaN                   3.0  \n",
       "2              x123                 NaN                   3.0  \n",
       "3              x123                 92%                   4.0  \n",
       "4              x123                 92%                   2.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the raw SAT results dataset\n",
    "data_path = '/Users/svitlanakovalivska/onboarding_weebet/_onboarding_data/daily_tasks/day_4/day_4_datasets/sat-results.csv'\n",
    "df_raw = pd.read_csv(data_path)\n",
    "\n",
    "print(\"=== RAW DATASET OVERVIEW ===\")\n",
    "print(f\"Dataset shape: {df_raw.shape}\")\n",
    "print(f\"\\nColumn names and types:\")\n",
    "print(df_raw.dtypes)\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quality_assessment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY ASSESSMENT ===\n",
      "Total rows: 493\n",
      "Total columns: 11\n",
      "Duplicate rows: 15\n",
      "\n",
      "=== MISSING VALUES BY COLUMN ===\n",
      "contact_extension: 105 (21.3%)\n",
      "pct_students_tested: 117 (23.7%)\n",
      "academic_tier_rating: 91 (18.5%)\n",
      "\n",
      "=== SUSPICIOUS VALUES IN SCORE COLUMNS ===\n",
      "Num of SAT Test Takers: ['s']\n",
      "SAT Critical Reading Avg. Score: ['s']\n",
      "SAT Math Avg. Score: ['s', '-10']\n",
      "SAT Writing Avg. Score: ['s']\n",
      "SAT Critical Readng Avg. Score: ['s']\n"
     ]
    }
   ],
   "source": [
    "# Data quality assessment\n",
    "def assess_data_quality(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Comprehensive data quality assessment function\n",
    "    Returns detailed statistics about data quality issues\n",
    "    \"\"\"\n",
    "    quality_report = {\n",
    "        'shape': df.shape,\n",
    "        'columns': list(df.columns),\n",
    "        'missing_values': df.isnull().sum().to_dict(),\n",
    "        'duplicate_rows': df.duplicated().sum(),\n",
    "        'column_stats': {}\n",
    "    }\n",
    "    \n",
    "    # Analyze each column\n",
    "    for col in df.columns:\n",
    "        stats = {\n",
    "            'dtype': str(df[col].dtype),\n",
    "            'unique_values': df[col].nunique(),\n",
    "            'sample_values': df[col].unique()[:10].tolist()\n",
    "        }\n",
    "        \n",
    "        # Check for suspicious values\n",
    "        if col in ['Num of SAT Test Takers', 'SAT Critical Reading Avg. Score', \n",
    "                  'SAT Math Avg. Score', 'SAT Writing Avg. Score', 'SAT Critical Readng Avg. Score']:\n",
    "            # Look for non-numeric values in score columns\n",
    "            non_numeric = df[col].astype(str).str.contains(r'[^0-9\\.]', na=False).sum()\n",
    "            stats['non_numeric_count'] = non_numeric\n",
    "            stats['suspicious_values'] = df[col][df[col].astype(str).str.contains(r'[^0-9\\.]', na=False)].unique().tolist()\n",
    "            \n",
    "        quality_report['column_stats'][col] = stats\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Perform quality assessment\n",
    "quality_report = assess_data_quality(df_raw)\n",
    "\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "print(f\"Total rows: {quality_report['shape'][0]}\")\n",
    "print(f\"Total columns: {quality_report['shape'][1]}\")\n",
    "print(f\"Duplicate rows: {quality_report['duplicate_rows']}\")\n",
    "\n",
    "print(f\"\\n=== MISSING VALUES BY COLUMN ===\")\n",
    "for col, missing_count in quality_report['missing_values'].items():\n",
    "    if missing_count > 0:\n",
    "        print(f\"{col}: {missing_count} ({missing_count/df_raw.shape[0]*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n=== SUSPICIOUS VALUES IN SCORE COLUMNS ===\")\n",
    "score_columns = ['Num of SAT Test Takers', 'SAT Critical Reading Avg. Score', \n",
    "                'SAT Math Avg. Score', 'SAT Writing Avg. Score', 'SAT Critical Readng Avg. Score']\n",
    "\n",
    "for col in score_columns:\n",
    "    if col in quality_report['column_stats']:\n",
    "        suspicious = quality_report['column_stats'][col]['suspicious_values']\n",
    "        if suspicious:\n",
    "            print(f\"{col}: {suspicious}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2_header",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "Based on the quality assessment, we need to address several data quality issues:\n",
    "\n",
    "1. **Remove duplicates**\n",
    "2. **Handle suppressed data (marked as 's')**\n",
    "3. **Fix invalid SAT scores (outliers like -10, 999, 1100)**\n",
    "4. **Standardize percentage formatting**\n",
    "5. **Remove the duplicate column with typo**\n",
    "6. **Handle missing values appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "data_cleaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPROVED DATA CLEANING PROCESS ===\n",
      "Step 1: Removed 15 duplicate rows\n",
      "Step 2: Removed duplicate column with typo\n",
      "Step 3: Cleaned SAT Critical Reading Avg. Score - 0 invalid scores\n",
      "Step 3: Cleaned SAT Math Avg. Score - 5 invalid scores\n",
      "Step 3: Cleaned SAT Writing Avg. Score - 0 invalid scores\n",
      "Step 4: REMOVED 62 rows without complete SAT scores (PRIMARY FILTER)\n",
      "Step 5: Validated test taker counts\n",
      "Step 6: Kept only 6 essential columns\n",
      "Step 7: Standardized column names\n",
      "Step 8: Added calculated total SAT score\n",
      "\n",
      "=== CLEANING COMPLETE ===\n",
      "Final dataset shape: (416, 7)\n",
      "Rows removed: 77\n",
      "Columns kept: ['dbn', 'school_name', 'sat_reading_avg', 'sat_math_avg', 'sat_writing_avg', 'num_test_takers', 'sat_total_avg']\n",
      "Data completeness: 100% for all SAT scores (by design)\n",
      "\n",
      "=== IMPROVED DATASET SUMMARY ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 416 entries, 0 to 477\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   dbn              416 non-null    object \n",
      " 1   school_name      416 non-null    object \n",
      " 2   sat_reading_avg  416 non-null    float64\n",
      " 3   sat_math_avg     416 non-null    float64\n",
      " 4   sat_writing_avg  416 non-null    float64\n",
      " 5   num_test_takers  416 non-null    int64  \n",
      " 6   sat_total_avg    416 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 26.0+ KB\n",
      "None\n",
      "\n",
      "=== SAMPLE OF CLEAN DATA ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbn</th>\n",
       "      <th>school_name</th>\n",
       "      <th>sat_reading_avg</th>\n",
       "      <th>sat_math_avg</th>\n",
       "      <th>sat_writing_avg</th>\n",
       "      <th>num_test_takers</th>\n",
       "      <th>sat_total_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>355.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>383.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>377.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>FORSYTH SATELLITE ACADEMY</td>\n",
       "      <td>414.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>390.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1207.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dbn                                    school_name  sat_reading_avg  \\\n",
       "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES            355.0   \n",
       "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL            383.0   \n",
       "2  01M450                     EAST SIDE COMMUNITY SCHOOL            377.0   \n",
       "3  01M458                      FORSYTH SATELLITE ACADEMY            414.0   \n",
       "4  01M509                        MARTA VALLE HIGH SCHOOL            390.0   \n",
       "\n",
       "   sat_math_avg  sat_writing_avg  num_test_takers  sat_total_avg  \n",
       "0         404.0            363.0               29         1122.0  \n",
       "1         423.0            366.0               91         1172.0  \n",
       "2         402.0            370.0               70         1149.0  \n",
       "3         401.0            359.0                7         1174.0  \n",
       "4         433.0            384.0               44         1207.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def improved_data_cleaning(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Improved data cleaning with logical filtering based on primary goal: SAT score analysis\n",
    "    \"\"\"\n",
    "    print(\"=== IMPROVED DATA CLEANING PROCESS ===\")\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Step 1: Remove exact duplicates\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    print(f\"Step 1: Removed {initial_rows - len(df_clean)} duplicate rows\")\n",
    "    \n",
    "    # Step 2: Remove the duplicate column with typo\n",
    "    if 'SAT Critical Readng Avg. Score' in df_clean.columns:\n",
    "        df_clean = df_clean.drop('SAT Critical Readng Avg. Score', axis=1)\n",
    "        print(\"Step 2: Removed duplicate column with typo\")\n",
    "    \n",
    "    # Step 3: Clean and validate SAT score columns (primary indicators)\n",
    "    sat_score_columns = ['SAT Critical Reading Avg. Score', 'SAT Math Avg. Score', 'SAT Writing Avg. Score']\n",
    "    \n",
    "    for col in sat_score_columns:\n",
    "        if col in df_clean.columns:\n",
    "            # Replace 's' (suppressed) with NaN\n",
    "            df_clean[col] = df_clean[col].replace('s', np.nan)\n",
    "            # Convert to numeric\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "            # Validate SAT score range (200-800)\n",
    "            valid_mask = (df_clean[col] >= 200) & (df_clean[col] <= 800) | df_clean[col].isna()\n",
    "            invalid_count = (~valid_mask).sum()\n",
    "            df_clean.loc[~valid_mask, col] = np.nan\n",
    "            print(f\"Step 3: Cleaned {col} - {invalid_count} invalid scores\")\n",
    "    \n",
    "    # Step 4: CRITICAL FILTER - Remove rows without complete SAT data\n",
    "    # This is our primary goal - SAT analysis requires all three scores\n",
    "    before_filter = len(df_clean)\n",
    "    sat_columns = ['SAT Critical Reading Avg. Score', 'SAT Math Avg. Score', 'SAT Writing Avg. Score']\n",
    "    df_clean = df_clean.dropna(subset=sat_columns)\n",
    "    removed_incomplete = before_filter - len(df_clean)\n",
    "    print(f\"Step 4: REMOVED {removed_incomplete} rows without complete SAT scores (PRIMARY FILTER)\")\n",
    "    \n",
    "    # Step 5: Clean number of test takers (important for statistical validity)\n",
    "    if 'Num of SAT Test Takers' in df_clean.columns:\n",
    "        df_clean['Num of SAT Test Takers'] = df_clean['Num of SAT Test Takers'].replace('s', np.nan)\n",
    "        df_clean['Num of SAT Test Takers'] = pd.to_numeric(df_clean['Num of SAT Test Takers'], errors='coerce')\n",
    "        # Filter reasonable values\n",
    "        valid_mask = (df_clean['Num of SAT Test Takers'] > 0) & (df_clean['Num of SAT Test Takers'] <= 2000)\n",
    "        df_clean = df_clean[valid_mask | df_clean['Num of SAT Test Takers'].isna()]\n",
    "        print(f\"Step 5: Validated test taker counts\")\n",
    "    \n",
    "    # Step 6: Keep only essential columns for SAT analysis\n",
    "    essential_columns = [\n",
    "        'DBN',\n",
    "        'SCHOOL NAME', \n",
    "        'SAT Critical Reading Avg. Score',\n",
    "        'SAT Math Avg. Score', \n",
    "        'SAT Writing Avg. Score',\n",
    "        'Num of SAT Test Takers'\n",
    "    ]\n",
    "    \n",
    "    # Filter to essential columns only\n",
    "    existing_essential = [col for col in essential_columns if col in df_clean.columns]\n",
    "    df_clean = df_clean[existing_essential]\n",
    "    print(f\"Step 6: Kept only {len(existing_essential)} essential columns\")\n",
    "    \n",
    "    # Step 7: Standardize column names\n",
    "    column_mapping = {\n",
    "        'DBN': 'dbn',\n",
    "        'SCHOOL NAME': 'school_name',\n",
    "        'SAT Critical Reading Avg. Score': 'sat_reading_avg',\n",
    "        'SAT Math Avg. Score': 'sat_math_avg', \n",
    "        'SAT Writing Avg. Score': 'sat_writing_avg',\n",
    "        'Num of SAT Test Takers': 'num_test_takers'\n",
    "    }\n",
    "    \n",
    "    df_clean = df_clean.rename(columns=column_mapping)\n",
    "    print(\"Step 7: Standardized column names\")\n",
    "    \n",
    "    # Step 8: Add calculated total score (computed, not stored separately)\n",
    "    df_clean['sat_total_avg'] = (df_clean['sat_reading_avg'] + \n",
    "                                df_clean['sat_math_avg'] + \n",
    "                                df_clean['sat_writing_avg'])\n",
    "    print(\"Step 8: Added calculated total SAT score\")\n",
    "    \n",
    "    print(f\"\\n=== CLEANING COMPLETE ===\")\n",
    "    print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "    print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
    "    print(f\"Columns kept: {list(df_clean.columns)}\")\n",
    "    print(f\"Data completeness: 100% for all SAT scores (by design)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Apply improved cleaning function\n",
    "df_improved = improved_data_cleaning(df_raw)\n",
    "\n",
    "# Display improved data info\n",
    "print(f\"\\n=== IMPROVED DATASET SUMMARY ===\")\n",
    "print(df_improved.info())\n",
    "print(f\"\\n=== SAMPLE OF CLEAN DATA ===\")\n",
    "df_improved.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3_header",
   "metadata": {},
   "source": [
    "## 3. Statistical Analysis and Data Exploration\n",
    "\n",
    "Now let's perform comprehensive statistical analysis to understand the patterns and distributions in our cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "statistical_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STATISTICAL ANALYSIS OF CLEANED DATA ===\n",
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "       num_of_sat_test_takers  sat_critical_reading_avg._score  \\\n",
      "count              421.000000                       421.000000   \n",
      "mean               110.320665                       400.850356   \n",
      "std                155.534254                        56.802783   \n",
      "min                  6.000000                       279.000000   \n",
      "25%                 41.000000                       368.000000   \n",
      "50%                 62.000000                       391.000000   \n",
      "75%                 95.000000                       416.000000   \n",
      "max               1277.000000                       679.000000   \n",
      "\n",
      "       sat_math_avg._score  sat_writing_avg._score  pct_students_tested  \\\n",
      "count           416.000000              421.000000           363.000000   \n",
      "mean            413.733173              393.985748            84.595041   \n",
      "std              64.945638               58.635109             5.673305   \n",
      "min             312.000000              286.000000            78.000000   \n",
      "25%             372.000000              360.000000            78.000000   \n",
      "50%             395.000000              381.000000            85.000000   \n",
      "75%             437.250000              411.000000            92.000000   \n",
      "max             735.000000              682.000000            92.000000   \n",
      "\n",
      "       academic_tier_rating  \n",
      "count            392.000000  \n",
      "mean               2.579082  \n",
      "std                1.128053  \n",
      "min                1.000000  \n",
      "25%                2.000000  \n",
      "50%                3.000000  \n",
      "75%                4.000000  \n",
      "max                4.000000  \n",
      "\n",
      "=== MISSING VALUE ANALYSIS ===\n",
      "num_of_sat_test_takers: 57 (11.9%)\n",
      "sat_critical_reading_avg._score: 57 (11.9%)\n",
      "sat_math_avg._score: 62 (13.0%)\n",
      "sat_writing_avg._score: 57 (11.9%)\n",
      "pct_students_tested: 115 (24.1%)\n",
      "academic_tier_rating: 86 (18.0%)\n",
      "\n",
      "=== SAT SCORE ANALYSIS ===\n",
      "Schools with complete SAT data: 416\n",
      "Average Total SAT Score: 1209.0\n",
      "Standard Deviation: 175.3\n",
      "Min Total SAT: 887.0\n",
      "Max Total SAT: 2096.0\n",
      "\n",
      "Total SAT Score Percentiles:\n",
      "  25th percentile: 1102\n",
      "  50th percentile: 1170\n",
      "  75th percentile: 1258\n",
      "  90th percentile: 1418\n",
      "  95th percentile: 1552\n",
      "\n",
      "=== ACADEMIC TIER RATING DISTRIBUTION ===\n",
      "  Tier 1: 90 schools (23.0%)\n",
      "  Tier 2: 96 schools (24.5%)\n",
      "  Tier 3: 95 schools (24.2%)\n",
      "  Tier 4: 111 schools (28.3%)\n",
      "\n",
      "=== SUMMARY STATISTICS TABLE ===\n",
      "       num_of_sat_test_takers  sat_critical_reading_avg._score  \\\n",
      "count                  421.00                           421.00   \n",
      "mean                   110.32                           400.85   \n",
      "std                    155.53                            56.80   \n",
      "min                      6.00                           279.00   \n",
      "25%                     41.00                           368.00   \n",
      "50%                     62.00                           391.00   \n",
      "75%                     95.00                           416.00   \n",
      "max                   1277.00                           679.00   \n",
      "\n",
      "       sat_math_avg._score  sat_writing_avg._score  pct_students_tested  \n",
      "count               416.00                  421.00               363.00  \n",
      "mean                413.73                  393.99                84.60  \n",
      "std                  64.95                   58.64                 5.67  \n",
      "min                 312.00                  286.00                78.00  \n",
      "25%                 372.00                  360.00                78.00  \n",
      "50%                 395.00                  381.00                85.00  \n",
      "75%                 437.25                  411.00                92.00  \n",
      "max                 735.00                  682.00                92.00  \n"
     ]
    }
   ],
   "source": [
    "# Statistical analysis of cleaned data\n",
    "def perform_statistical_analysis(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Comprehensive statistical analysis of SAT score data\n",
    "    \"\"\"\n",
    "    print(\"=== STATISTICAL ANALYSIS OF CLEANED DATA ===\")\n",
    "    \n",
    "    # Basic statistics for numeric columns\n",
    "    numeric_cols = ['num_of_sat_test_takers', 'sat_critical_reading_avg._score', \n",
    "                   'sat_math_avg._score', 'sat_writing_avg._score', \n",
    "                   'pct_students_tested', 'academic_tier_rating']\n",
    "    \n",
    "    # Filter existing columns\n",
    "    existing_numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
    "    \n",
    "    if existing_numeric_cols:\n",
    "        print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "        print(df[existing_numeric_cols].describe())\n",
    "        \n",
    "        # Missing value analysis\n",
    "        print(f\"\\n=== MISSING VALUE ANALYSIS ===\")\n",
    "        missing_analysis = df[existing_numeric_cols].isnull().sum()\n",
    "        for col, missing_count in missing_analysis.items():\n",
    "            missing_pct = (missing_count / len(df)) * 100\n",
    "            print(f\"{col}: {missing_count} ({missing_pct:.1f}%)\")\n",
    "        \n",
    "        # SAT Score Analysis\n",
    "        sat_cols = [col for col in existing_numeric_cols if 'sat_' in col and 'score' in col]\n",
    "        if sat_cols:\n",
    "            print(f\"\\n=== SAT SCORE ANALYSIS ===\")\n",
    "            \n",
    "            # Calculate total SAT scores where all sections are available\n",
    "            complete_scores = df[sat_cols].dropna()\n",
    "            if not complete_scores.empty:\n",
    "                complete_scores['total_sat'] = complete_scores.sum(axis=1)\n",
    "                \n",
    "                print(f\"Schools with complete SAT data: {len(complete_scores)}\")\n",
    "                print(f\"Average Total SAT Score: {complete_scores['total_sat'].mean():.1f}\")\n",
    "                print(f\"Standard Deviation: {complete_scores['total_sat'].std():.1f}\")\n",
    "                print(f\"Min Total SAT: {complete_scores['total_sat'].min()}\")\n",
    "                print(f\"Max Total SAT: {complete_scores['total_sat'].max()}\")\n",
    "                \n",
    "                # Score distribution by percentiles\n",
    "                percentiles = [25, 50, 75, 90, 95]\n",
    "                print(f\"\\nTotal SAT Score Percentiles:\")\n",
    "                for p in percentiles:\n",
    "                    score = np.percentile(complete_scores['total_sat'], p)\n",
    "                    print(f\"  {p}th percentile: {score:.0f}\")\n",
    "        \n",
    "        # Academic tier analysis\n",
    "        if 'academic_tier_rating' in df.columns:\n",
    "            print(f\"\\n=== ACADEMIC TIER RATING DISTRIBUTION ===\")\n",
    "            tier_counts = df['academic_tier_rating'].value_counts().sort_index()\n",
    "            for tier, count in tier_counts.items():\n",
    "                pct = (count / len(df.dropna(subset=['academic_tier_rating']))) * 100\n",
    "                print(f\"  Tier {int(tier)}: {count} schools ({pct:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Perform statistical analysis\n",
    "df_analyzed = perform_statistical_analysis(df_cleaned)\n",
    "\n",
    "# Create summary statistics table for key metrics\n",
    "numeric_columns = ['num_of_sat_test_takers', 'sat_critical_reading_avg._score', \n",
    "                  'sat_math_avg._score', 'sat_writing_avg._score', 'pct_students_tested']\n",
    "existing_cols = [col for col in numeric_columns if col in df_cleaned.columns]\n",
    "\n",
    "if existing_cols:\n",
    "    summary_stats = df_cleaned[existing_cols].describe().round(2)\n",
    "    print(f\"\\n=== SUMMARY STATISTICS TABLE ===\")\n",
    "    print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4_header",
   "metadata": {},
   "source": [
    "## 4. Database Schema Design and Integration\n",
    "\n",
    "Now let's design the optimal database schema for integrating the SAT results with existing tables and establish the database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "database_connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database connection successful!\n",
      "PostgreSQL version: PostgreSQL 17.5 on aarch64-unknown-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n",
      "\n",
      "=== EXISTING TABLES IN nyc_schools SCHEMA ===\n",
      "  - Levon_cleaned_sat_scores\n",
      "  - anastasia_sat_results\n",
      "  - clara_sat_results\n",
      "  - deepshikha_sat_results\n",
      "  - giovani_sat_results\n",
      "  - high_school_directory\n",
      "  - jyoti_sat_results\n",
      "  - najimohammed_sat_results\n",
      "  - sat_scores\n",
      "  - sat_scores_mariia\n",
      "  - school_demographics\n",
      "  - school_safety_report\n",
      "  - sebastian_sat_results\n",
      "  - sultan_sat_results\n",
      "  - sumi_sat_results\n",
      "  - svitlana_experement_sat_results\n",
      "  - svitlana_sat_results\n",
      "  - svitlana_test_connection\n"
     ]
    }
   ],
   "source": [
    "# Database connection setup\n",
    "DATABASE_URL = (\n",
    "    \"postgresql+psycopg2://neondb_owner:npg_CeS9fJg2azZD\"\n",
    "    \"@ep-falling-glitter-a5m0j5gk-pooler.us-east-2.aws.neon.tech:5432/neondb\"\n",
    "    \"?sslmode=require\"\n",
    ")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Test database connection\n",
    "try:\n",
    "    # Test connection\n",
    "    with engine.connect() as connection:\n",
    "        # Import text for SQL queries - FIXED\n",
    "        from sqlalchemy import text\n",
    "        \n",
    "        result = connection.execute(text(\"SELECT version()\"))\n",
    "        version = result.fetchone()[0]\n",
    "        print(f\"‚úÖ Database connection successful!\")\n",
    "        print(f\"PostgreSQL version: {version}\")\n",
    "        \n",
    "        # Check existing tables in nyc_schools schema\n",
    "        result = connection.execute(text(\"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'nyc_schools'\n",
    "            ORDER BY table_name;\n",
    "        \"\"\"))\n",
    "        tables = result.fetchall()\n",
    "        print(f\"\\n=== EXISTING TABLES IN nyc_schools SCHEMA ===\")\n",
    "        for table in tables:\n",
    "            print(f\"  - {table[0]}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "prepare_database",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARING CLEAN DATA FOR DATABASE ===\n",
      "Clean database schema columns: ['dbn', 'school_name', 'sat_reading_avg', 'sat_math_avg', 'sat_writing_avg', 'num_test_takers', 'sat_total_avg', 'data_processed_at']\n",
      "Records prepared for insertion: 416\n",
      "Data completeness: 100% for all SAT scores\n",
      "\n",
      "=== FINAL CLEAN DATABASE SCHEMA ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 416 entries, 0 to 477\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   dbn                416 non-null    object        \n",
      " 1   school_name        416 non-null    object        \n",
      " 2   sat_reading_avg    416 non-null    float64       \n",
      " 3   sat_math_avg       416 non-null    float64       \n",
      " 4   sat_writing_avg    416 non-null    float64       \n",
      " 5   num_test_takers    416 non-null    int64         \n",
      " 6   sat_total_avg      416 non-null    float64       \n",
      " 7   data_processed_at  416 non-null    datetime64[us]\n",
      "dtypes: datetime64[us](1), float64(4), int64(1), object(2)\n",
      "memory usage: 29.2+ KB\n",
      "None\n",
      "\n",
      "=== SAMPLE CLEAN RECORDS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbn</th>\n",
       "      <th>school_name</th>\n",
       "      <th>sat_reading_avg</th>\n",
       "      <th>sat_math_avg</th>\n",
       "      <th>sat_writing_avg</th>\n",
       "      <th>num_test_takers</th>\n",
       "      <th>sat_total_avg</th>\n",
       "      <th>data_processed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>355.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>2025-08-07 22:40:56.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>383.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>2025-08-07 22:40:56.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>377.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>2025-08-07 22:40:56.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>FORSYTH SATELLITE ACADEMY</td>\n",
       "      <td>414.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>2025-08-07 22:40:56.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>390.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>2025-08-07 22:40:56.847458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dbn                                    school_name  sat_reading_avg  \\\n",
       "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES            355.0   \n",
       "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL            383.0   \n",
       "2  01M450                     EAST SIDE COMMUNITY SCHOOL            377.0   \n",
       "3  01M458                      FORSYTH SATELLITE ACADEMY            414.0   \n",
       "4  01M509                        MARTA VALLE HIGH SCHOOL            390.0   \n",
       "\n",
       "   sat_math_avg  sat_writing_avg  num_test_takers  sat_total_avg  \\\n",
       "0         404.0            363.0               29         1122.0   \n",
       "1         423.0            366.0               91         1172.0   \n",
       "2         402.0            370.0               70         1149.0   \n",
       "3         401.0            359.0                7         1174.0   \n",
       "4         433.0            384.0               44         1207.0   \n",
       "\n",
       "           data_processed_at  \n",
       "0 2025-08-07 22:40:56.847458  \n",
       "1 2025-08-07 22:40:56.847458  \n",
       "2 2025-08-07 22:40:56.847458  \n",
       "3 2025-08-07 22:40:56.847458  \n",
       "4 2025-08-07 22:40:56.847458  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare improved clean data for database insertion\n",
    "def prepare_clean_data_for_database(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the logically cleaned dataset for database insertion\n",
    "    Focus on essential SAT analysis data only\n",
    "    \"\"\"\n",
    "    print(\"=== PREPARING CLEAN DATA FOR DATABASE ===\")\n",
    "    \n",
    "    # The data is already clean - just add minimal metadata for tracking\n",
    "    df_db = df.copy()\n",
    "    \n",
    "    # Add only essential metadata\n",
    "    df_db['data_processed_at'] = pd.Timestamp.now()\n",
    "    \n",
    "    print(f\"Clean database schema columns: {list(df_db.columns)}\")\n",
    "    print(f\"Records prepared for insertion: {len(df_db)}\")\n",
    "    print(f\"Data completeness: 100% for all SAT scores\")\n",
    "    \n",
    "    return df_db\n",
    "\n",
    "# Prepare final clean dataset\n",
    "df_final_clean = prepare_clean_data_for_database(df_improved)\n",
    "\n",
    "# Display final clean schema\n",
    "print(f\"\\n=== FINAL CLEAN DATABASE SCHEMA ===\")\n",
    "print(df_final_clean.info())\n",
    "print(f\"\\n=== SAMPLE CLEAN RECORDS ===\")\n",
    "df_final_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5_header",
   "metadata": {},
   "source": [
    "## 5. Database Insertion with Error Handling\n",
    "\n",
    "Now let's insert the cleaned data into the PostgreSQL database with proper error handling and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "database_insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INSERTING CLEAN SAT DATA TO DATABASE ===\n",
      "Table: nyc_schools.svitlana_sat_scores_clean\n",
      "Clean records to insert: 416\n",
      "Data completeness: 100% SAT scores (by design)\n",
      "‚úÖ Successfully inserted 416 clean records into nyc_schools.svitlana_sat_scores_clean\n",
      "‚úÖ Verification: 416 records found in database table\n",
      "\n",
      "=== TOP 3 SCHOOLS BY SAT TOTAL ===\n",
      "1. 02M475 - STUYVESANT HIGH SCHOOL...\n",
      "   Reading: 679.0, Math: 735.0, Writing: 682.0, Total: 2096.0\n",
      "2. 10X445 - BRONX HIGH SCHOOL OF SCIENCE...\n",
      "   Reading: 632.0, Math: 688.0, Writing: 649.0, Total: 1969.0\n",
      "3. 31R605 - STATEN ISLAND TECHNICAL HIGH SCHOOL...\n",
      "   Reading: 635.0, Math: 682.0, Writing: 636.0, Total: 1953.0\n",
      "\n",
      "üéØ IMPROVED DATA INTEGRATION COMPLETED!\n",
      "   ‚úÖ Logical filtering: Only schools with complete SAT data\n",
      "   ‚úÖ Essential columns only: Focused on SAT analysis purpose\n",
      "   ‚úÖ Clean dataset: 416 high-quality records\n",
      "   ‚úÖ 100% data completeness for primary indicators (SAT scores)\n",
      "   ‚úÖ Removed unnecessary metadata and irrelevant columns\n"
     ]
    }
   ],
   "source": [
    "# Database insertion with improved clean dataset\n",
    "def insert_clean_data_to_database(df: pd.DataFrame, table_name: str = 'svitlana_sat_scores_clean') -> bool:\n",
    "    \"\"\"\n",
    "    Insert the logically cleaned SAT data to PostgreSQL database\n",
    "    Only includes schools with complete SAT score data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"=== INSERTING CLEAN SAT DATA TO DATABASE ===\")\n",
    "        print(f\"Table: nyc_schools.{table_name}\")\n",
    "        print(f\"Clean records to insert: {len(df)}\")\n",
    "        print(f\"Data completeness: 100% SAT scores (by design)\")\n",
    "        \n",
    "        # Insert clean data using pandas to_sql\n",
    "        result = df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            schema='nyc_schools',\n",
    "            if_exists='replace',  # Replace existing table\n",
    "            index=False,\n",
    "            method='multi'  # Use efficient batch insertion\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Successfully inserted {len(df)} clean records into nyc_schools.{table_name}\")\n",
    "        \n",
    "        # Verify insertion\n",
    "        with engine.connect() as connection:\n",
    "            from sqlalchemy import text\n",
    "            \n",
    "            verification_query = text(f\"SELECT COUNT(*) FROM nyc_schools.{table_name}\")\n",
    "            result = connection.execute(verification_query)\n",
    "            count = result.fetchone()[0]\n",
    "            print(f\"‚úÖ Verification: {count} records found in database table\")\n",
    "            \n",
    "            # Get sample of inserted data with SAT statistics\n",
    "            sample_query = text(f\"\"\"\n",
    "                SELECT dbn, school_name, sat_reading_avg, sat_math_avg, sat_writing_avg, sat_total_avg\n",
    "                FROM nyc_schools.{table_name} \n",
    "                ORDER BY sat_total_avg DESC \n",
    "                LIMIT 3\n",
    "            \"\"\")\n",
    "            sample_result = connection.execute(sample_query)\n",
    "            sample_data = sample_result.fetchall()\n",
    "            \n",
    "            print(f\"\\n=== TOP 3 SCHOOLS BY SAT TOTAL ===\")\n",
    "            for i, row in enumerate(sample_data, 1):\n",
    "                print(f\"{i}. {row[0]} - {row[1][:40]}...\")\n",
    "                print(f\"   Reading: {row[2]}, Math: {row[3]}, Writing: {row[4]}, Total: {row[5]}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Database insertion failed: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        return False\n",
    "\n",
    "# Insert improved clean dataset\n",
    "success_clean = insert_clean_data_to_database(df_final_clean)\n",
    "\n",
    "if success_clean:\n",
    "    print(f\"\\nüéØ IMPROVED DATA INTEGRATION COMPLETED!\")\n",
    "    print(f\"   ‚úÖ Logical filtering: Only schools with complete SAT data\")\n",
    "    print(f\"   ‚úÖ Essential columns only: Focused on SAT analysis purpose\")  \n",
    "    print(f\"   ‚úÖ Clean dataset: {len(df_final_clean)} high-quality records\")\n",
    "    print(f\"   ‚úÖ 100% data completeness for primary indicators (SAT scores)\")\n",
    "    print(f\"   ‚úÖ Removed unnecessary metadata and irrelevant columns\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Clean database insertion failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6_header",
   "metadata": {},
   "source": [
    "## 6. Export Cleaned Data\n",
    "\n",
    "Finally, let's export the cleaned dataset as a CSV file for backup and further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "export_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully exported cleaned data to: /Users/svitlanakovalivska/onboarding_weebet/_onboarding_data/svitlana_experement_sat_results.csv\n",
      "   - Records exported: 478\n",
      "   - Columns exported: 13\n",
      "   - File size: 172.1 KB\n",
      "\n",
      "=== DATA CLEANING SUMMARY REPORT ===\n",
      "Original dataset:\n",
      "  - Rows: 493\n",
      "  - Columns: 11\n",
      "  - Duplicates: 15\n",
      "\n",
      "Cleaned dataset:\n",
      "  - Rows: 478\n",
      "  - Columns: 13\n",
      "  - Data quality improvements:\n",
      "    * Removed duplicate rows: 15\n",
      "    * Standardized column names\n",
      "    * Converted percentages to proper format (0-100)\n",
      "    * Validated SAT score ranges (200-800)\n",
      "    * Handled suppressed data appropriately\n",
      "    * Added calculated total SAT scores\n",
      "    * Added metadata columns\n",
      "\n",
      "Data completeness:\n",
      "  - Schools with complete SAT data: 416 (87.0%)\n",
      "  - Average total SAT score: 1209.0\n",
      "\n",
      "üéØ TASK COMPLETION STATUS:\n",
      "‚úÖ Data exploration and quality assessment completed\n",
      "‚úÖ Comprehensive data cleaning applied\n",
      "‚úÖ Statistical analysis performed\n",
      "‚úÖ Database schema designed and data inserted\n",
      "‚úÖ Cleaned dataset exported to CSV\n",
      "\n",
      "üöÄ Ready for production use and further analysis!\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned data to CSV\n",
    "output_path = '/Users/svitlanakovalivska/onboarding_weebet/_onboarding_data/svitlana_experement_sat_results.csv'\n",
    "\n",
    "try:\n",
    "    # Export final cleaned dataset\n",
    "    df_final.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Successfully exported cleaned data to: {output_path}\")\n",
    "    print(f\"   - Records exported: {len(df_final)}\")\n",
    "    print(f\"   - Columns exported: {len(df_final.columns)}\")\n",
    "    print(f\"   - File size: {df_final.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    # Create summary report\n",
    "    print(f\"\\n=== DATA CLEANING SUMMARY REPORT ===\")\n",
    "    print(f\"Original dataset:\")\n",
    "    print(f\"  - Rows: {len(df_raw)}\")\n",
    "    print(f\"  - Columns: {len(df_raw.columns)}\")\n",
    "    print(f\"  - Duplicates: {df_raw.duplicated().sum()}\")\n",
    "    \n",
    "    print(f\"\\nCleaned dataset:\")\n",
    "    print(f\"  - Rows: {len(df_final)}\")\n",
    "    print(f\"  - Columns: {len(df_final.columns)}\")\n",
    "    print(f\"  - Data quality improvements:\")\n",
    "    print(f\"    * Removed duplicate rows: {len(df_raw) - len(df_cleaned)}\")\n",
    "    print(f\"    * Standardized column names\")\n",
    "    print(f\"    * Converted percentages to proper format (0-100)\")\n",
    "    print(f\"    * Validated SAT score ranges (200-800)\")\n",
    "    print(f\"    * Handled suppressed data appropriately\")\n",
    "    print(f\"    * Added calculated total SAT scores\")\n",
    "    print(f\"    * Added metadata columns\")\n",
    "    \n",
    "    # Data quality metrics\n",
    "    complete_records = df_final.dropna(subset=['sat_critical_reading_avg_score', 'sat_math_avg_score', 'sat_writing_avg_score'])\n",
    "    print(f\"\\nData completeness:\")\n",
    "    print(f\"  - Schools with complete SAT data: {len(complete_records)} ({len(complete_records)/len(df_final)*100:.1f}%)\")\n",
    "    \n",
    "    if not complete_records.empty:\n",
    "        avg_total = complete_records['sat_total_avg_score'].mean()\n",
    "        print(f\"  - Average total SAT score: {avg_total:.1f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to export cleaned data: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ TASK COMPLETION STATUS:\")\n",
    "print(f\"‚úÖ Data exploration and quality assessment completed\") \n",
    "print(f\"‚úÖ Comprehensive data cleaning applied\")\n",
    "print(f\"‚úÖ Statistical analysis performed\")\n",
    "print(f\"‚úÖ Database schema designed and data inserted\")\n",
    "print(f\"‚úÖ Cleaned dataset exported to CSV\")\n",
    "print(f\"\\nüöÄ Ready for production use and further analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
