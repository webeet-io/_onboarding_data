{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4. Data Integration & Schema Design: NYC SAT Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective\n",
    "Learn how to evaluate, clean, and integrate a real-world dataset into an existing PostgreSQL schema. You'll inspect the dataset, identify relational keys, clean inconsistencies, and write a Python-based script to append the data into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "1. Explore the Dataset\n",
    "\n",
    "Open the CSV and review its structure\n",
    "Refer to: daily_tasks/day_4/day_4_datasets/readme.md\n",
    "Identify which columns are useful and which are synthetic or dirty\n",
    "\n",
    "2. Clean the Data Using Python\n",
    "\n",
    "Handle duplicates, invalid SAT scores, and inconsistent formatting (e.g., \"85%\"), weird outliers and any inconsistencies\n",
    "Normalize headers and drop unrelated fields\n",
    "\n",
    "3. Design the Schema\n",
    "\n",
    "Choose columns to upload to the database\n",
    "\n",
    "4. Write a Python Script to Append Data\n",
    "\n",
    "Use psycopg2 or sqlalchemy to connect\n",
    "Append cleaned data to your sat_scores table\n",
    "Use parameterized queries and commit logic\n",
    "\n",
    "5. Save Your Work\n",
    "\n",
    "In your branch (e.g., [your-name]/day-4), go to:\n",
    "üìÅ daily_tasks/day_4/day_4_task/\n",
    "\n",
    "Add:\n",
    "\n",
    "cleaned_sat_results.csv - output as clean csv file\n",
    "sat_modeling.ipynb ‚Äì your dataset cleaning and database insertion script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy connection string format:\n",
    "# postgresql+psycopg2://user:password@host:port/dbname\n",
    "\n",
    "DATABASE_URL = (\n",
    "    \"postgresql+psycopg2://neondb_owner:npg_CeS9fJg2azZD\"\n",
    "    \"@ep-falling-glitter-a5m0j5gk-pooler.us-east-2.aws.neon.tech:5432/neondb\"\n",
    "    \"?sslmode=require\"\n",
    ")\n",
    "\n",
    "# Create engine and establish connection\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>SCHOOL NAME</th>\n",
       "      <th>Num of SAT Test Takers</th>\n",
       "      <th>SAT Critical Reading Avg. Score</th>\n",
       "      <th>SAT Math Avg. Score</th>\n",
       "      <th>SAT Writing Avg. Score</th>\n",
       "      <th>SAT Critical Readng Avg. Score</th>\n",
       "      <th>internal_school_id</th>\n",
       "      <th>contact_extension</th>\n",
       "      <th>pct_students_tested</th>\n",
       "      <th>academic_tier_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>29</td>\n",
       "      <td>355</td>\n",
       "      <td>404</td>\n",
       "      <td>363</td>\n",
       "      <td>355</td>\n",
       "      <td>218160</td>\n",
       "      <td>x345</td>\n",
       "      <td>78%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "      <td>423</td>\n",
       "      <td>366</td>\n",
       "      <td>383</td>\n",
       "      <td>268547</td>\n",
       "      <td>x234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>70</td>\n",
       "      <td>377</td>\n",
       "      <td>402</td>\n",
       "      <td>370</td>\n",
       "      <td>377</td>\n",
       "      <td>236446</td>\n",
       "      <td>x123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>FORSYTH SATELLITE ACADEMY</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>414</td>\n",
       "      <td>427826</td>\n",
       "      <td>x123</td>\n",
       "      <td>92%</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>44</td>\n",
       "      <td>390</td>\n",
       "      <td>433</td>\n",
       "      <td>384</td>\n",
       "      <td>390</td>\n",
       "      <td>672714</td>\n",
       "      <td>x123</td>\n",
       "      <td>92%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>27Q480</td>\n",
       "      <td>JOHN ADAMS HIGH SCHOOL</td>\n",
       "      <td>403</td>\n",
       "      <td>391</td>\n",
       "      <td>409</td>\n",
       "      <td>392</td>\n",
       "      <td>391</td>\n",
       "      <td>863765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92%</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>13K605</td>\n",
       "      <td>GEORGE WESTINGHOUSE CAREER AND TECHNICAL EDUCA...</td>\n",
       "      <td>85</td>\n",
       "      <td>406</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>406</td>\n",
       "      <td>937579</td>\n",
       "      <td>x234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>05M304</td>\n",
       "      <td>MOTT HALL HIGH SCHOOL</td>\n",
       "      <td>54</td>\n",
       "      <td>413</td>\n",
       "      <td>399</td>\n",
       "      <td>398</td>\n",
       "      <td>413</td>\n",
       "      <td>296405</td>\n",
       "      <td>x123</td>\n",
       "      <td>78%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>02M520</td>\n",
       "      <td>MURRY BERGTRAUM HIGH SCHOOL FOR BUSINESS CAREERS</td>\n",
       "      <td>264</td>\n",
       "      <td>407</td>\n",
       "      <td>440</td>\n",
       "      <td>393</td>\n",
       "      <td>407</td>\n",
       "      <td>892839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>07X221</td>\n",
       "      <td>SOUTH BRONX PREPARATORY: A COLLEGE BOARD SCHOOL</td>\n",
       "      <td>65</td>\n",
       "      <td>364</td>\n",
       "      <td>378</td>\n",
       "      <td>348</td>\n",
       "      <td>364</td>\n",
       "      <td>277389</td>\n",
       "      <td>x345</td>\n",
       "      <td>92%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DBN                                        SCHOOL NAME  \\\n",
       "0    01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
       "1    01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
       "2    01M450                         EAST SIDE COMMUNITY SCHOOL   \n",
       "3    01M458                          FORSYTH SATELLITE ACADEMY   \n",
       "4    01M509                            MARTA VALLE HIGH SCHOOL   \n",
       "..      ...                                                ...   \n",
       "488  27Q480                             JOHN ADAMS HIGH SCHOOL   \n",
       "489  13K605  GEORGE WESTINGHOUSE CAREER AND TECHNICAL EDUCA...   \n",
       "490  05M304                              MOTT HALL HIGH SCHOOL   \n",
       "491  02M520   MURRY BERGTRAUM HIGH SCHOOL FOR BUSINESS CAREERS   \n",
       "492  07X221    SOUTH BRONX PREPARATORY: A COLLEGE BOARD SCHOOL   \n",
       "\n",
       "    Num of SAT Test Takers SAT Critical Reading Avg. Score  \\\n",
       "0                       29                             355   \n",
       "1                       91                             383   \n",
       "2                       70                             377   \n",
       "3                        7                             414   \n",
       "4                       44                             390   \n",
       "..                     ...                             ...   \n",
       "488                    403                             391   \n",
       "489                     85                             406   \n",
       "490                     54                             413   \n",
       "491                    264                             407   \n",
       "492                     65                             364   \n",
       "\n",
       "    SAT Math Avg. Score SAT Writing Avg. Score SAT Critical Readng Avg. Score  \\\n",
       "0                   404                    363                            355   \n",
       "1                   423                    366                            383   \n",
       "2                   402                    370                            377   \n",
       "3                   401                    359                            414   \n",
       "4                   433                    384                            390   \n",
       "..                  ...                    ...                            ...   \n",
       "488                 409                    392                            391   \n",
       "489                 391                    392                            406   \n",
       "490                 399                    398                            413   \n",
       "491                 440                    393                            407   \n",
       "492                 378                    348                            364   \n",
       "\n",
       "     internal_school_id contact_extension pct_students_tested  \\\n",
       "0                218160              x345                 78%   \n",
       "1                268547              x234                 NaN   \n",
       "2                236446              x123                 NaN   \n",
       "3                427826              x123                 92%   \n",
       "4                672714              x123                 92%   \n",
       "..                  ...               ...                 ...   \n",
       "488              863765               NaN                 92%   \n",
       "489              937579              x234                 NaN   \n",
       "490              296405              x123                 78%   \n",
       "491              892839               NaN                 92%   \n",
       "492              277389              x345                 92%   \n",
       "\n",
       "     academic_tier_rating  \n",
       "0                     2.0  \n",
       "1                     3.0  \n",
       "2                     3.0  \n",
       "3                     4.0  \n",
       "4                     2.0  \n",
       "..                    ...  \n",
       "488                   1.0  \n",
       "489                   NaN  \n",
       "490                   2.0  \n",
       "491                   2.0  \n",
       "492                   NaN  \n",
       "\n",
       "[493 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open the CSV and review its structure\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/Users/svitlanakovalivska/onboarding_weebet/_onboarding_data-1/daily_tasks/day_4/day_4_datasets/sat-results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493 entries, 0 to 492\n",
      "Data columns (total 11 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              493 non-null    object \n",
      " 1   SCHOOL NAME                      493 non-null    object \n",
      " 2   Num of SAT Test Takers           493 non-null    object \n",
      " 3   SAT Critical Reading Avg. Score  493 non-null    object \n",
      " 4   SAT Math Avg. Score              493 non-null    object \n",
      " 5   SAT Writing Avg. Score           493 non-null    object \n",
      " 6   SAT Critical Readng Avg. Score   493 non-null    object \n",
      " 7   internal_school_id               493 non-null    int64  \n",
      " 8   contact_extension                388 non-null    object \n",
      " 9   pct_students_tested              376 non-null    object \n",
      " 10  academic_tier_rating             402 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 42.5+ KB\n",
      "Number of duplicate rows: 15\n",
      "Unique values in each column:\n",
      "DBN: 478\n",
      "SCHOOL NAME: 478\n",
      "Num of SAT Test Takers: 175\n",
      "SAT Critical Reading Avg. Score: 164\n",
      "SAT Math Avg. Score: 177\n",
      "SAT Writing Avg. Score: 163\n",
      "SAT Critical Readng Avg. Score: 164\n",
      "internal_school_id: 478\n",
      "contact_extension: 3\n",
      "pct_students_tested: 3\n",
      "academic_tier_rating: 4\n",
      "Missing values in each column:\n",
      "DBN                                  0\n",
      "SCHOOL NAME                          0\n",
      "Num of SAT Test Takers               0\n",
      "SAT Critical Reading Avg. Score      0\n",
      "SAT Math Avg. Score                  0\n",
      "SAT Writing Avg. Score               0\n",
      "SAT Critical Readng Avg. Score       0\n",
      "internal_school_id                   0\n",
      "contact_extension                  105\n",
      "pct_students_tested                117\n",
      "academic_tier_rating                91\n",
      "dtype: int64\n",
      "Descriptive statistics for internal_school_id:\n",
      "count       493.000000\n",
      "mean     562172.943205\n",
      "std      262138.627055\n",
      "min      101855.000000\n",
      "25%      332013.000000\n",
      "50%      587220.000000\n",
      "75%      782993.000000\n",
      "max      999398.000000\n",
      "Name: internal_school_id, dtype: float64\n",
      "\n",
      "\n",
      "Descriptive statistics for academic_tier_rating:\n",
      "count    402.000000\n",
      "mean       2.564677\n",
      "std        1.126443\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        4.000000\n",
      "max        4.000000\n",
      "Name: academic_tier_rating, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identify which columns are useful and which are synthetic or dirty\n",
    "\n",
    "# Check for null values and data types\n",
    "df.info()\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Check for unique values in each column\n",
    "unique_values = {col: df[col].nunique() for col in df.columns}\n",
    "print(\"Unique values in each column:\")\n",
    "for col, count in unique_values.items():\n",
    "    print(f\"{col}: {count}\")        \n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Check for outliers in numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_cols:\n",
    "    print(f\"Descriptive statistics for {col}:\")\n",
    "    print(df[col].describe())\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicated column names found.\n",
      "The columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' are identical.\n"
     ]
    }
   ],
   "source": [
    "#Identify which columns are useful and which are synthetic or dirty\n",
    "\n",
    "#Check the duplicated column names  \n",
    "duplicated_columns = df.columns[df.columns.duplicated()].tolist()\n",
    "if duplicated_columns:\n",
    "    print(\"Duplicated column names found:\")\n",
    "    print(duplicated_columns)\n",
    "else:\n",
    "    print(\"No duplicated column names found.\")  \n",
    "\n",
    "#Check if 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' columns are identical\n",
    "if 'SAT Critical Reading Avg. Score' in df.columns and 'SAT Critical Readng Avg. Score' in df.columns:\n",
    "    if df['SAT Critical Reading Avg. Score'].equals(df['SAT Critical Readng Avg. Score']):\n",
    "        print(\"The columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' are identical.\")\n",
    "    else:\n",
    "        print(\"The columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' are different.\")\n",
    "else:\n",
    "    print(\"One or both of the columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' do not exist in the DataFrame.\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INVESTIGATION: Why are numerical columns showing as 'object' type? ===\n",
      "\n",
      "üîç INVESTIGATING COLUMN: Num of SAT Test Takers\n",
      "   Data type: object\n",
      "   Sample values: ['29' '91' '70' '7' '44' '112' '159' '18' '130' '16']\n",
      "   ‚ùå Non-numeric values found: ['s']\n",
      "   ‚ùå Count of non-numeric values: 58\n",
      "------------------------------------------------------------\n",
      "üîç INVESTIGATING COLUMN: SAT Critical Reading Avg. Score\n",
      "   Data type: object\n",
      "   Sample values: ['355' '383' '377' '414' '390' '332' '522' '417' '624' '395']\n",
      "   ‚ùå Non-numeric values found: ['s']\n",
      "   ‚ùå Count of non-numeric values: 58\n",
      "------------------------------------------------------------\n",
      "üîç INVESTIGATING COLUMN: SAT Math Avg. Score\n",
      "   Data type: object\n",
      "   Sample values: ['404' '423' '402' '401' '433' '557' '574' '418' '604' '400']\n",
      "   ‚ùå Non-numeric values found: ['s']\n",
      "   ‚ùå Count of non-numeric values: 58\n",
      "------------------------------------------------------------\n",
      "üîç INVESTIGATING COLUMN: SAT Writing Avg. Score\n",
      "   Data type: object\n",
      "   Sample values: ['363' '366' '370' '359' '384' '316' '525' '411' '628' '387']\n",
      "   ‚ùå Non-numeric values found: ['s']\n",
      "   ‚ùå Count of non-numeric values: 58\n",
      "------------------------------------------------------------\n",
      "üîç INVESTIGATING COLUMN: SAT Critical Readng Avg. Score\n",
      "   Data type: object\n",
      "   Sample values: ['355' '383' '377' '414' '390' '332' '522' '417' '624' '395']\n",
      "   ‚ùå Non-numeric values found: ['s']\n",
      "   ‚ùå Count of non-numeric values: 58\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== INVESTIGATING PERCENTAGE COLUMN ===\n",
      "üîç INVESTIGATING COLUMN: pct_students_tested\n",
      "   Data type: object\n",
      "   Sample values: ['78%' '92%' '85%']\n",
      "   Missing values: 117\n",
      "\n",
      "=== SUMMARY OF DATA QUALITY ISSUES ===\n",
      "1. üìä DUPLICATE ROWS: 15 duplicate rows found\n",
      "2. üî§ COLUMN NAME TYPO: 'SAT Critical Readng Avg. Score' (missing 'i')\n",
      "3. üî¢ TYPE ISSUES: Numerical columns stored as 'object' type\n",
      "4. üï≥Ô∏è MISSING DATA:\n",
      "   - contact_extension: 105 missing\n",
      "   - pct_students_tested: 117 missing\n",
      "   - academic_tier_rating: 91 missing\n",
      "5. üéØ SCHOOL IDENTIFICATION: DBN and internal_school_id seem to be unique identifiers\n"
     ]
    }
   ],
   "source": [
    "# üìä COMPREHENSIVE DATA QUALITY INVESTIGATION\n",
    "\n",
    "print(\"=== INVESTIGATION: Why are numerical columns showing as 'object' type? ===\\n\")\n",
    "\n",
    "# 1. Investigate SAT score columns that should be numerical\n",
    "sat_columns = ['Num of SAT Test Takers', 'SAT Critical Reading Avg. Score', \n",
    "               'SAT Math Avg. Score', 'SAT Writing Avg. Score', 'SAT Critical Readng Avg. Score']\n",
    "\n",
    "for col in sat_columns:\n",
    "    print(f\"üîç INVESTIGATING COLUMN: {col}\")\n",
    "    print(f\"   Data type: {df[col].dtype}\")\n",
    "    \n",
    "    # Check for non-numeric values\n",
    "    sample_values = df[col].unique()[:10]  # First 10 unique values\n",
    "    print(f\"   Sample values: {sample_values}\")\n",
    "    \n",
    "    # Try to convert to numeric and see what fails\n",
    "    numeric_errors = pd.to_numeric(df[col], errors='coerce')\n",
    "    non_numeric_mask = df[col] != numeric_errors.astype(str)\n",
    "    non_numeric_values = df[col][pd.to_numeric(df[col], errors='coerce').isna()]\n",
    "    \n",
    "    if len(non_numeric_values) > 0:\n",
    "        print(f\"   ‚ùå Non-numeric values found: {non_numeric_values.unique()}\")\n",
    "        print(f\"   ‚ùå Count of non-numeric values: {len(non_numeric_values)}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ All values appear numeric\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n=== INVESTIGATING PERCENTAGE COLUMN ===\")\n",
    "print(f\"üîç INVESTIGATING COLUMN: pct_students_tested\")\n",
    "print(f\"   Data type: {df['pct_students_tested'].dtype}\")\n",
    "print(f\"   Sample values: {df['pct_students_tested'].dropna().unique()}\")\n",
    "print(f\"   Missing values: {df['pct_students_tested'].isna().sum()}\")\n",
    "\n",
    "print(\"\\n=== SUMMARY OF DATA QUALITY ISSUES ===\")\n",
    "print(\"1. üìä DUPLICATE ROWS: 15 duplicate rows found\")\n",
    "print(\"2. üî§ COLUMN NAME TYPO: 'SAT Critical Readng Avg. Score' (missing 'i')\")\n",
    "print(\"3. üî¢ TYPE ISSUES: Numerical columns stored as 'object' type\")\n",
    "print(\"4. üï≥Ô∏è MISSING DATA:\")\n",
    "print(f\"   - contact_extension: {df['contact_extension'].isna().sum()} missing\")\n",
    "print(f\"   - pct_students_tested: {df['pct_students_tested'].isna().sum()} missing\") \n",
    "print(f\"   - academic_tier_rating: {df['academic_tier_rating'].isna().sum()} missing\")\n",
    "print(\"5. üéØ SCHOOL IDENTIFICATION: DBN and internal_school_id seem to be unique identifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INVESTIGATING THE MYSTERIOUS 's' VALUES ===\n",
      "\n",
      "üìä Found 58 rows with 's' values\n",
      "\n",
      "üìã Sample of schools with 's' values:\n",
      "       DBN                                  SCHOOL NAME  \\\n",
      "22  02M392                   MANHATTAN BUSINESS ACADEMY   \n",
      "23  02M393                    BUSINESS OF SPORTS SCHOOL   \n",
      "25  02M399   THE HIGH SCHOOL FOR LANGUAGE AND DIPLOMACY   \n",
      "38  02M427        MANHATTAN ACADEMY FOR ARTS & LANGUAGE   \n",
      "40  02M437  HUDSON HIGH SCHOOL OF LEARNING TECHNOLOGIES   \n",
      "\n",
      "   Num of SAT Test Takers SAT Critical Reading Avg. Score  \n",
      "22                      s                               s  \n",
      "23                      s                               s  \n",
      "25                      s                               s  \n",
      "38                      s                               s  \n",
      "40                      s                               s  \n",
      "\n",
      "ü§î HYPOTHESIS: 's' likely means 'suppressed' data\n",
      "   - Common in educational datasets when numbers are too small to report\n",
      "   - Usually indicates < 5 students to protect privacy\n",
      "   - All SAT columns have same 58 's' values - confirms this pattern\n",
      "\n",
      "=== PERCENTAGE COLUMN ANALYSIS ===\n",
      "üîç pct_students_tested column:\n",
      "   Values: ['78%' '92%' '85%']\n",
      "   ‚úÖ Format: All values end with '%' - need to remove % and convert to float\n",
      "\n",
      "=== CONTACT EXTENSION ANALYSIS ===\n",
      "üîç contact_extension column:\n",
      "   Values: ['x345' 'x234' 'x123']\n",
      "   ü§î Only 3 unique values, many missing - probably not useful for analysis\n",
      "\n",
      "=== DATA CLEANING STRATEGY ===\n",
      "1. üßπ Remove 15 duplicate rows\n",
      "2. üî§ Fix column name: 'SAT Critical Readng Avg. Score' ‚Üí 'SAT Critical Reading Avg. Score'\n",
      "3. üî¢ Handle 's' values in SAT columns:\n",
      "   - Option A: Replace with NaN (recommended)\n",
      "   - Option B: Replace with 0 (not recommended)\n",
      "   - Option C: Drop these rows entirely\n",
      "4. üìä Convert percentage column: Remove '%' and convert to float\n",
      "5. üî¢ Convert all SAT score columns to numeric\n",
      "6. üóëÔ∏è Consider dropping contact_extension (too many missing, limited unique values)\n"
     ]
    }
   ],
   "source": [
    "# üîç DEEPER INVESTIGATION: Understanding the 's' values\n",
    "\n",
    "print(\"=== INVESTIGATING THE MYSTERIOUS 's' VALUES ===\\n\")\n",
    "\n",
    "# Find rows where SAT scores are 's'\n",
    "s_mask = df['Num of SAT Test Takers'] == 's'\n",
    "s_rows = df[s_mask]\n",
    "\n",
    "print(f\"üìä Found {len(s_rows)} rows with 's' values\")\n",
    "print(\"\\nüìã Sample of schools with 's' values:\")\n",
    "print(s_rows[['DBN', 'SCHOOL NAME', 'Num of SAT Test Takers', 'SAT Critical Reading Avg. Score']].head())\n",
    "\n",
    "print(f\"\\nü§î HYPOTHESIS: 's' likely means 'suppressed' data\")\n",
    "print(\"   - Common in educational datasets when numbers are too small to report\")\n",
    "print(\"   - Usually indicates < 5 students to protect privacy\")\n",
    "print(\"   - All SAT columns have same 58 's' values - confirms this pattern\")\n",
    "\n",
    "print(\"\\n=== PERCENTAGE COLUMN ANALYSIS ===\")\n",
    "print(\"üîç pct_students_tested column:\")\n",
    "pct_values = df['pct_students_tested'].dropna().unique()\n",
    "print(f\"   Values: {pct_values}\")\n",
    "print(\"   ‚úÖ Format: All values end with '%' - need to remove % and convert to float\")\n",
    "\n",
    "print(\"\\n=== CONTACT EXTENSION ANALYSIS ===\")\n",
    "print(\"üîç contact_extension column:\")\n",
    "ext_values = df['contact_extension'].dropna().unique()\n",
    "print(f\"   Values: {ext_values}\")\n",
    "print(\"   ü§î Only 3 unique values, many missing - probably not useful for analysis\")\n",
    "\n",
    "print(\"\\n=== DATA CLEANING STRATEGY ===\")\n",
    "print(\"1. üßπ Remove 15 duplicate rows\")\n",
    "print(\"2. üî§ Fix column name: 'SAT Critical Readng Avg. Score' ‚Üí 'SAT Critical Reading Avg. Score'\")\n",
    "print(\"3. üî¢ Handle 's' values in SAT columns:\")\n",
    "print(\"   - Option A: Replace with NaN (recommended)\")\n",
    "print(\"   - Option B: Replace with 0 (not recommended)\")\n",
    "print(\"   - Option C: Drop these rows entirely\")\n",
    "print(\"4. üìä Convert percentage column: Remove '%' and convert to float\")\n",
    "print(\"5. üî¢ Convert all SAT score columns to numeric\")\n",
    "print(\"6. üóëÔ∏è Consider dropping contact_extension (too many missing, limited unique values)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDATION OF CLEANED DATASET ===\n",
      "\n",
      "1. ‚úÖ DATA TYPES VALIDATION:\n",
      "   Num of SAT Test Takers: float64 ‚úÖ\n",
      "   SAT Critical Reading Avg. Score: float64 ‚úÖ\n",
      "   SAT Math Avg. Score: float64 ‚úÖ\n",
      "   SAT Writing Avg. Score: float64 ‚úÖ\n",
      "   pct_students_tested: float64 ‚úÖ\n",
      "\n",
      "2. üìä SAT SCORE RANGE VALIDATION:\n",
      "   SAT Critical Reading Avg. Score:\n",
      "     Range: 279 - 679 ‚úÖ Valid range\n",
      "     Mean: 400.9\n",
      "   SAT Math Avg. Score:\n",
      "     Range: -10 - 1100 ‚ùå Invalid range\n",
      "     Mean: 418.2\n",
      "   SAT Writing Avg. Score:\n",
      "     Range: 286 - 682 ‚úÖ Valid range\n",
      "     Mean: 394.0\n",
      "\n",
      "3. üìà PERCENTAGE VALIDATION:\n",
      "   pct_students_tested: 78% - 92% ‚úÖ Valid percentage range\n",
      "\n",
      "4. üîç REMAINING DATA QUALITY CHECKS:\n",
      "   Duplicate rows: 0 ‚úÖ\n",
      "   Unique schools (DBN): 478\n",
      "   Unique schools (internal_school_id): 478\n",
      "\n",
      "5. üìä CLEANED DATA SUMMARY:\n",
      "       Num of SAT Test Takers  SAT Critical Reading Avg. Score  \\\n",
      "count              421.000000                       421.000000   \n",
      "mean               110.320665                       400.850356   \n",
      "std                155.534254                        56.802783   \n",
      "min                  6.000000                       279.000000   \n",
      "25%                 41.000000                       368.000000   \n",
      "50%                 62.000000                       391.000000   \n",
      "75%                 95.000000                       416.000000   \n",
      "max               1277.000000                       679.000000   \n",
      "\n",
      "       SAT Math Avg. Score  SAT Writing Avg. Score  internal_school_id  \\\n",
      "count           421.000000              421.000000          478.000000   \n",
      "mean            418.173397              393.985748       560082.717573   \n",
      "std              88.210494               58.635109       259637.064755   \n",
      "min             -10.000000              286.000000       101855.000000   \n",
      "25%             372.000000              360.000000       337012.500000   \n",
      "50%             395.000000              381.000000       581301.500000   \n",
      "75%             438.000000              411.000000       778312.750000   \n",
      "max            1100.000000              682.000000       999398.000000   \n",
      "\n",
      "       pct_students_tested  academic_tier_rating  \n",
      "count           363.000000            392.000000  \n",
      "mean             84.595041              2.579082  \n",
      "std               5.673305              1.128053  \n",
      "min              78.000000              1.000000  \n",
      "25%              78.000000              2.000000  \n",
      "50%              85.000000              3.000000  \n",
      "75%              92.000000              4.000000  \n",
      "max              92.000000              4.000000  \n",
      "\n",
      "=== FINAL DATASET READY FOR DATABASE! ===\n",
      "‚úÖ Dataset shape: (478, 9)\n",
      "‚úÖ All numerical columns properly typed\n",
      "‚úÖ No duplicate rows\n",
      "‚úÖ Valid SAT score ranges (200-800)\n",
      "‚úÖ Valid percentage ranges (0-100%)\n",
      "‚úÖ Missing values properly handled as NaN\n"
     ]
    }
   ],
   "source": [
    "# üîç VALIDATION & FINAL ANALYSIS OF CLEANED DATA\n",
    "\n",
    "print(\"=== VALIDATION OF CLEANED DATASET ===\\n\")\n",
    "\n",
    "# 1. Check data types are now correct\n",
    "print(\"1. ‚úÖ DATA TYPES VALIDATION:\")\n",
    "numeric_cols = ['Num of SAT Test Takers', 'SAT Critical Reading Avg. Score', \n",
    "                'SAT Math Avg. Score', 'SAT Writing Avg. Score', 'pct_students_tested']\n",
    "for col in numeric_cols:\n",
    "    if col in df_cleaned.columns:\n",
    "        print(f\"   {col}: {df_cleaned[col].dtype} ‚úÖ\")\n",
    "\n",
    "# 2. Check SAT score ranges are reasonable\n",
    "print(\"\\n2. üìä SAT SCORE RANGE VALIDATION:\")\n",
    "sat_score_cols = ['SAT Critical Reading Avg. Score', 'SAT Math Avg. Score', 'SAT Writing Avg. Score']\n",
    "for col in sat_score_cols:\n",
    "    valid_scores = df_cleaned[col].dropna()\n",
    "    min_score = valid_scores.min()\n",
    "    max_score = valid_scores.max()\n",
    "    mean_score = valid_scores.mean()\n",
    "    \n",
    "    # SAT scores should be between 200-800\n",
    "    if min_score >= 200 and max_score <= 800:\n",
    "        status = \"‚úÖ Valid range\"\n",
    "    else:\n",
    "        status = \"‚ùå Invalid range\"\n",
    "    \n",
    "    print(f\"   {col}:\")\n",
    "    print(f\"     Range: {min_score:.0f} - {max_score:.0f} {status}\")\n",
    "    print(f\"     Mean: {mean_score:.1f}\")\n",
    "\n",
    "# 3. Check percentage values\n",
    "print(\"\\n3. üìà PERCENTAGE VALIDATION:\")\n",
    "if 'pct_students_tested' in df_cleaned.columns:\n",
    "    pct_valid = df_cleaned['pct_students_tested'].dropna()\n",
    "    pct_min = pct_valid.min()\n",
    "    pct_max = pct_valid.max()\n",
    "    \n",
    "    if pct_min >= 0 and pct_max <= 100:\n",
    "        status = \"‚úÖ Valid percentage range\"\n",
    "    else:\n",
    "        status = \"‚ùå Invalid percentage range\"\n",
    "    \n",
    "    print(f\"   pct_students_tested: {pct_min:.0f}% - {pct_max:.0f}% {status}\")\n",
    "\n",
    "# 4. Check for remaining data quality issues\n",
    "print(\"\\n4. üîç REMAINING DATA QUALITY CHECKS:\")\n",
    "print(f\"   Duplicate rows: {df_cleaned.duplicated().sum()} ‚úÖ\")\n",
    "print(f\"   Unique schools (DBN): {df_cleaned['DBN'].nunique()}\")\n",
    "print(f\"   Unique schools (internal_school_id): {df_cleaned['internal_school_id'].nunique()}\")\n",
    "\n",
    "# 5. Summary statistics for cleaned data\n",
    "print(\"\\n5. üìä CLEANED DATA SUMMARY:\")\n",
    "print(df_cleaned.describe())\n",
    "\n",
    "print(\"\\n=== FINAL DATASET READY FOR DATABASE! ===\")\n",
    "print(f\"‚úÖ Dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"‚úÖ All numerical columns properly typed\")\n",
    "print(f\"‚úÖ No duplicate rows\")\n",
    "print(f\"‚úÖ Valid SAT score ranges (200-800)\")\n",
    "print(f\"‚úÖ Valid percentage ranges (0-100%)\")\n",
    "print(f\"‚úÖ Missing values properly handled as NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã CLEANED DATASET PREVIEW:\n",
      "      DBN                                    SCHOOL NAME  \\\n",
      "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
      "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
      "\n",
      "   Num of SAT Test Takers  SAT Critical Reading Avg. Score  \\\n",
      "0                    29.0                            355.0   \n",
      "1                    91.0                            383.0   \n",
      "2                    70.0                            377.0   \n",
      "3                     7.0                            414.0   \n",
      "4                    44.0                            390.0   \n",
      "\n",
      "   SAT Math Avg. Score  SAT Writing Avg. Score  internal_school_id  \\\n",
      "0                404.0                   363.0              218160   \n",
      "1                423.0                   366.0              268547   \n",
      "2                402.0                   370.0              236446   \n",
      "3                401.0                   359.0              427826   \n",
      "4                433.0                   384.0              672714   \n",
      "\n",
      "   pct_students_tested  academic_tier_rating  \n",
      "0                 78.0                   2.0  \n",
      "1                  NaN                   3.0  \n",
      "2                  NaN                   3.0  \n",
      "3                 92.0                   4.0  \n",
      "4                 92.0                   2.0  \n",
      "\n",
      "üìä CLEANED DATASET INFO:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 478 entries, 0 to 477\n",
      "Data columns (total 9 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              478 non-null    object \n",
      " 1   SCHOOL NAME                      478 non-null    object \n",
      " 2   Num of SAT Test Takers           421 non-null    float64\n",
      " 3   SAT Critical Reading Avg. Score  421 non-null    float64\n",
      " 4   SAT Math Avg. Score              421 non-null    float64\n",
      " 5   SAT Writing Avg. Score           421 non-null    float64\n",
      " 6   internal_school_id               478 non-null    int64  \n",
      " 7   pct_students_tested              363 non-null    float64\n",
      " 8   academic_tier_rating             392 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 37.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned dataset\n",
    "print(\"üìã CLEANED DATASET PREVIEW:\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "print(f\"\\nüìä CLEANED DATASET INFO:\")\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean the Data Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPLEMENTING DATA CLEANING STRATEGY ===\n",
      "\n",
      "1. üßπ Removing duplicate rows...\n",
      "   ‚úÖ Removed 15 duplicate rows\n",
      "   üìä Rows: 493 ‚Üí 478\n",
      "\n",
      "2. üî§ Fixing column name typo...\n",
      "   ‚úÖ Dropped duplicate column 'SAT Critical Readng Avg. Score'\n",
      "\n",
      "3. üî¢ Handling 's' values in SAT columns...\n",
      "   ‚úÖ Replaced 228 's' values with NaN across SAT columns\n",
      "\n",
      "4. üìä Converting percentage column...\n",
      "   ‚úÖ Converted pct_students_tested from '85%' format to numeric\n",
      "\n",
      "5. üî¢ Converting SAT columns to numeric...\n",
      "   ‚úÖ Converted Num of SAT Test Takers to numeric type\n",
      "   ‚úÖ Converted SAT Critical Reading Avg. Score to numeric type\n",
      "   ‚úÖ Converted SAT Math Avg. Score to numeric type\n",
      "   ‚úÖ Converted SAT Writing Avg. Score to numeric type\n",
      "\n",
      "6. üóëÔ∏è Dropping contact_extension column...\n",
      "   ‚úÖ Dropped contact_extension column (105 missing values, only 3 unique values)\n",
      "\n",
      "=== CLEANING RESULTS ===\n",
      "üìä Final dataset shape: (478, 9)\n",
      "üî¢ Data types after cleaning:\n",
      "DBN                                 object\n",
      "SCHOOL NAME                         object\n",
      "Num of SAT Test Takers             float64\n",
      "SAT Critical Reading Avg. Score    float64\n",
      "SAT Math Avg. Score                float64\n",
      "SAT Writing Avg. Score             float64\n",
      "internal_school_id                   int64\n",
      "pct_students_tested                float64\n",
      "academic_tier_rating               float64\n",
      "dtype: object\n",
      "\n",
      "üï≥Ô∏è Missing values after cleaning:\n",
      "Num of SAT Test Takers              57\n",
      "SAT Critical Reading Avg. Score     57\n",
      "SAT Math Avg. Score                 57\n",
      "SAT Writing Avg. Score              57\n",
      "pct_students_tested                115\n",
      "academic_tier_rating                86\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# üßπ COMPREHENSIVE DATA CLEANING IMPLEMENTATION\n",
    "\n",
    "print(\"=== IMPLEMENTING DATA CLEANING STRATEGY ===\\n\")\n",
    "\n",
    "# Start with a copy of the original data\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# 1. Remove duplicate rows\n",
    "print(\"1. üßπ Removing duplicate rows...\")\n",
    "initial_rows = len(df_cleaned)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "duplicates_removed = initial_rows - len(df_cleaned)\n",
    "print(f\"   ‚úÖ Removed {duplicates_removed} duplicate rows\")\n",
    "print(f\"   üìä Rows: {initial_rows} ‚Üí {len(df_cleaned)}\")\n",
    "\n",
    "# 2. Fix column name typo\n",
    "print(\"\\n2. üî§ Fixing column name typo...\")\n",
    "if 'SAT Critical Readng Avg. Score' in df_cleaned.columns:\n",
    "    df_cleaned = df_cleaned.drop(columns=['SAT Critical Readng Avg. Score'])\n",
    "    print(\"   ‚úÖ Dropped duplicate column 'SAT Critical Readng Avg. Score'\")\n",
    "\n",
    "# 3. Handle 's' values in SAT columns (replace with NaN)\n",
    "print(\"\\n3. üî¢ Handling 's' values in SAT columns...\")\n",
    "sat_columns = ['Num of SAT Test Takers', 'SAT Critical Reading Avg. Score', \n",
    "               'SAT Math Avg. Score', 'SAT Writing Avg. Score']\n",
    "\n",
    "s_count = 0\n",
    "for col in sat_columns:\n",
    "    s_mask = df_cleaned[col] == 's'\n",
    "    s_count += s_mask.sum()\n",
    "    df_cleaned.loc[s_mask, col] = None  # Replace 's' with NaN\n",
    "    \n",
    "print(f\"   ‚úÖ Replaced {s_count} 's' values with NaN across SAT columns\")\n",
    "\n",
    "# 4. Convert percentage column\n",
    "print(\"\\n4. üìä Converting percentage column...\")\n",
    "if 'pct_students_tested' in df_cleaned.columns:\n",
    "    # Remove % and convert to float\n",
    "    df_cleaned['pct_students_tested'] = df_cleaned['pct_students_tested'].str.replace('%', '').astype(float)\n",
    "    print(\"   ‚úÖ Converted pct_students_tested from '85%' format to numeric\")\n",
    "\n",
    "# 5. Convert SAT columns to numeric\n",
    "print(\"\\n5. üî¢ Converting SAT columns to numeric...\")\n",
    "for col in sat_columns:\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "    print(f\"   ‚úÖ Converted {col} to numeric type\")\n",
    "\n",
    "# 6. Drop contact_extension (too many missing values, limited usefulness)\n",
    "print(\"\\n6. üóëÔ∏è Dropping contact_extension column...\")\n",
    "if 'contact_extension' in df_cleaned.columns:\n",
    "    df_cleaned = df_cleaned.drop(columns=['contact_extension'])\n",
    "    print(\"   ‚úÖ Dropped contact_extension column (105 missing values, only 3 unique values)\")\n",
    "\n",
    "print(\"\\n=== CLEANING RESULTS ===\")\n",
    "print(f\"üìä Final dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"üî¢ Data types after cleaning:\")\n",
    "print(df_cleaned.dtypes)\n",
    "\n",
    "print(f\"\\nüï≥Ô∏è Missing values after cleaning:\")\n",
    "missing_after = df_cleaned.isnull().sum()\n",
    "print(missing_after[missing_after > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Design the Schema\n",
    "\n",
    "Now we'll choose which columns to upload to the database and design our table structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèóÔ∏è SCHEMA DESIGN FOR DATABASE\n",
    "\n",
    "print(\"=== DESIGNING DATABASE SCHEMA ===\\n\")\n",
    "\n",
    "print(\"üìã COLUMNS SELECTED FOR DATABASE:\")\n",
    "print(\"‚úÖ DBN - School identifier (VARCHAR, PRIMARY KEY candidate)\")\n",
    "print(\"‚úÖ SCHOOL NAME - School name (VARCHAR)\")\n",
    "print(\"‚úÖ Num of SAT Test Takers - Number of students (INTEGER)\")\n",
    "print(\"‚úÖ SAT Critical Reading Avg. Score - Reading score (INTEGER)\")\n",
    "print(\"‚úÖ SAT Math Avg. Score - Math score (INTEGER)\")\n",
    "print(\"‚úÖ SAT Writing Avg. Score - Writing score (INTEGER)\")\n",
    "print(\"‚úÖ internal_school_id - Internal ID (INTEGER)\")\n",
    "print(\"‚úÖ pct_students_tested - Percentage tested (DECIMAL)\")\n",
    "print(\"‚úÖ academic_tier_rating - Academic rating (DECIMAL)\")\n",
    "\n",
    "print(\"\\nüìä FINAL COLUMNS FOR DATABASE UPLOAD:\")\n",
    "columns_for_db = df_cleaned.columns.tolist()\n",
    "for i, col in enumerate(columns_for_db, 1):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "print(f\"\\nüéØ TOTAL COLUMNS: {len(columns_for_db)}\")\n",
    "print(f\"üéØ TOTAL ROWS: {len(df_cleaned)}\")\n",
    "\n",
    "# Show sample of final data structure\n",
    "print(\"\\nüìù SAMPLE DATA FOR DATABASE:\")\n",
    "print(df_cleaned.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write a Python Script to Append Data\n",
    "\n",
    "Upload the cleaned data to the PostgreSQL database using SQLAlchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÑÔ∏è DATABASE UPLOAD IMPLEMENTATION\n",
    "\n",
    "print(\"=== UPLOADING CLEANED DATA TO DATABASE ===\\n\")\n",
    "\n",
    "try:\n",
    "    # Upload cleaned data to database\n",
    "    table_name = 'svitlana_sat_results'  # Using your name as specified in the task\n",
    "    schema_name = 'nyc_schools'\n",
    "    \n",
    "    print(f\"üì§ Uploading data to table: {schema_name}.{table_name}\")\n",
    "    print(f\"üìä Uploading {len(df_cleaned)} rows with {len(df_cleaned.columns)} columns\")\n",
    "    \n",
    "    # Upload to database\n",
    "    df_cleaned.to_sql(\n",
    "        name=table_name,       \n",
    "        con=engine,     \n",
    "        schema=schema_name,\n",
    "        if_exists='replace',    # Replace table if it exists\n",
    "        index=False,           # Don't include pandas index\n",
    "        method='multi'         # Use multi-row insert for better performance\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ SUCCESS: Data uploaded to database!\")\n",
    "    print(f\"‚úÖ Table created: {schema_name}.{table_name}\")\n",
    "    \n",
    "    # Verify upload by counting rows\n",
    "    verification_query = f\"SELECT COUNT(*) FROM {schema_name}.{table_name}\"\n",
    "    result = engine.execute(verification_query).fetchone()\n",
    "    row_count = result[0]\n",
    "    \n",
    "    print(f\"‚úÖ VERIFICATION: {row_count} rows found in database table\")\n",
    "    \n",
    "    if row_count == len(df_cleaned):\n",
    "        print(\"üéâ All rows successfully uploaded!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Warning: Expected {len(df_cleaned)} rows, but found {row_count}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR uploading to database: {str(e)}\")\n",
    "    print(\"Please check your database connection and permissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save Your Work\n",
    "\n",
    "Export the cleaned dataset as CSV file as required by the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ EXPORT CLEANED DATA AS CSV\n",
    "\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/Users/svitlanakovalivska/onboarding_weebet/_onboarding_data-1/daily_tasks/day_4'\n",
    "csv_filename = 'cleaned_sat_results.csv'\n",
    "csv_path = os.path.join(output_dir, csv_filename)\n",
    "\n",
    "print(\"=== EXPORTING CLEANED DATA ===\\n\")\n",
    "\n",
    "try:\n",
    "    # Export cleaned data to CSV\n",
    "    df_cleaned.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ SUCCESS: Cleaned data exported to CSV!\")\n",
    "    print(f\"üìÅ File location: {csv_path}\")\n",
    "    print(f\"üìä Exported {len(df_cleaned)} rows and {len(df_cleaned.columns)} columns\")\n",
    "    \n",
    "    # Verify file was created\n",
    "    if os.path.exists(csv_path):\n",
    "        file_size = os.path.getsize(csv_path)\n",
    "        print(f\"‚úÖ File size: {file_size:,} bytes\")\n",
    "    else:\n",
    "        print(\"‚ùå Warning: CSV file not found after export\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR exporting CSV: {str(e)}\")\n",
    "\n",
    "print(\"\\nüéâ TASK COMPLETED!\")\n",
    "print(\"üìã Summary of deliverables:\")\n",
    "print(\"‚úÖ Data exploration and quality analysis completed\")\n",
    "print(\"‚úÖ Comprehensive data cleaning implemented\")\n",
    "print(\"‚úÖ Schema designed for database upload\")\n",
    "print(\"‚úÖ Data uploaded to PostgreSQL database\")\n",
    "print(\"‚úÖ Cleaned dataset exported as CSV\")\n",
    "print(\"\\nüéØ Ready for submission in your branch!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
