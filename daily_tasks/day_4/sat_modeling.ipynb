{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4. Data Integration & Schema Design: NYC SAT Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective\n",
    "Learn how to evaluate, clean, and integrate a real-world dataset into an existing PostgreSQL schema. You'll inspect the dataset, identify relational keys, clean inconsistencies, and write a Python-based script to append the data into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals:\n",
    "\n",
    "- Inspect and understand the structure of the dataset.\n",
    "- Select meaningful and relational columns that link to existing tables.\n",
    "- Identify issues in the data such as duplicates, outliers, or formatting inconsistencies.\n",
    "- Clean and preprocess the data using Python.\n",
    "- Prepare the data for database insertion.\n",
    "- Write a Python script that connects to the database and appends the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "1. Explore the Dataset\n",
    "\n",
    "Open the CSV and review its structure\n",
    "Refer to: daily_tasks/day_4/day_4_datasets/readme.md\n",
    "Identify which columns are useful and which are synthetic or dirty\n",
    "\n",
    "2. Clean the Data Using Python\n",
    "\n",
    "Handle duplicates, invalid SAT scores, and inconsistent formatting (e.g., \"85%\"), weird outliers and any inconsistencies\n",
    "Normalize headers and drop unrelated fields\n",
    "\n",
    "3. Design the Schema\n",
    "\n",
    "Choose columns to upload to the database\n",
    "\n",
    "4. Write a Python Script to Append Data\n",
    "\n",
    "Use psycopg2 or sqlalchemy to connect\n",
    "Append cleaned data to your sat_scores table\n",
    "Use parameterized queries and commit logic\n",
    "\n",
    "5. Save Your Work\n",
    "\n",
    "In your branch (e.g., [your-name]/day-4), go to:\n",
    "üìÅ daily_tasks/day_4/day_4_task/\n",
    "\n",
    "Add:\n",
    "\n",
    "cleaned_sat_results.csv - output as clean csv file\n",
    "sat_modeling.ipynb ‚Äì your dataset cleaning and database insertion script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy connection string format:\n",
    "# postgresql+psycopg2://user:password@host:port/dbname\n",
    "\n",
    "DATABASE_URL = (\n",
    "    \"postgresql+psycopg2://neondb_owner:npg_CeS9fJg2azZD\"\n",
    "    \"@ep-falling-glitter-a5m0j5gk-pooler.us-east-2.aws.neon.tech:5432/neondb\"\n",
    "    \"?sslmode=require\"\n",
    ")\n",
    "\n",
    "# Create engine and establish connection\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>SCHOOL NAME</th>\n",
       "      <th>Num of SAT Test Takers</th>\n",
       "      <th>SAT Critical Reading Avg. Score</th>\n",
       "      <th>SAT Math Avg. Score</th>\n",
       "      <th>SAT Writing Avg. Score</th>\n",
       "      <th>SAT Critical Readng Avg. Score</th>\n",
       "      <th>internal_school_id</th>\n",
       "      <th>contact_extension</th>\n",
       "      <th>pct_students_tested</th>\n",
       "      <th>academic_tier_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>29</td>\n",
       "      <td>355</td>\n",
       "      <td>404</td>\n",
       "      <td>363</td>\n",
       "      <td>355</td>\n",
       "      <td>218160</td>\n",
       "      <td>x345</td>\n",
       "      <td>78%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "      <td>423</td>\n",
       "      <td>366</td>\n",
       "      <td>383</td>\n",
       "      <td>268547</td>\n",
       "      <td>x234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>70</td>\n",
       "      <td>377</td>\n",
       "      <td>402</td>\n",
       "      <td>370</td>\n",
       "      <td>377</td>\n",
       "      <td>236446</td>\n",
       "      <td>x123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>FORSYTH SATELLITE ACADEMY</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>414</td>\n",
       "      <td>427826</td>\n",
       "      <td>x123</td>\n",
       "      <td>92%</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>44</td>\n",
       "      <td>390</td>\n",
       "      <td>433</td>\n",
       "      <td>384</td>\n",
       "      <td>390</td>\n",
       "      <td>672714</td>\n",
       "      <td>x123</td>\n",
       "      <td>92%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>27Q480</td>\n",
       "      <td>JOHN ADAMS HIGH SCHOOL</td>\n",
       "      <td>403</td>\n",
       "      <td>391</td>\n",
       "      <td>409</td>\n",
       "      <td>392</td>\n",
       "      <td>391</td>\n",
       "      <td>863765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92%</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>13K605</td>\n",
       "      <td>GEORGE WESTINGHOUSE CAREER AND TECHNICAL EDUCA...</td>\n",
       "      <td>85</td>\n",
       "      <td>406</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>406</td>\n",
       "      <td>937579</td>\n",
       "      <td>x234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>05M304</td>\n",
       "      <td>MOTT HALL HIGH SCHOOL</td>\n",
       "      <td>54</td>\n",
       "      <td>413</td>\n",
       "      <td>399</td>\n",
       "      <td>398</td>\n",
       "      <td>413</td>\n",
       "      <td>296405</td>\n",
       "      <td>x123</td>\n",
       "      <td>78%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>02M520</td>\n",
       "      <td>MURRY BERGTRAUM HIGH SCHOOL FOR BUSINESS CAREERS</td>\n",
       "      <td>264</td>\n",
       "      <td>407</td>\n",
       "      <td>440</td>\n",
       "      <td>393</td>\n",
       "      <td>407</td>\n",
       "      <td>892839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92%</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>07X221</td>\n",
       "      <td>SOUTH BRONX PREPARATORY: A COLLEGE BOARD SCHOOL</td>\n",
       "      <td>65</td>\n",
       "      <td>364</td>\n",
       "      <td>378</td>\n",
       "      <td>348</td>\n",
       "      <td>364</td>\n",
       "      <td>277389</td>\n",
       "      <td>x345</td>\n",
       "      <td>92%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DBN                                        SCHOOL NAME  \\\n",
       "0    01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
       "1    01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
       "2    01M450                         EAST SIDE COMMUNITY SCHOOL   \n",
       "3    01M458                          FORSYTH SATELLITE ACADEMY   \n",
       "4    01M509                            MARTA VALLE HIGH SCHOOL   \n",
       "..      ...                                                ...   \n",
       "488  27Q480                             JOHN ADAMS HIGH SCHOOL   \n",
       "489  13K605  GEORGE WESTINGHOUSE CAREER AND TECHNICAL EDUCA...   \n",
       "490  05M304                              MOTT HALL HIGH SCHOOL   \n",
       "491  02M520   MURRY BERGTRAUM HIGH SCHOOL FOR BUSINESS CAREERS   \n",
       "492  07X221    SOUTH BRONX PREPARATORY: A COLLEGE BOARD SCHOOL   \n",
       "\n",
       "    Num of SAT Test Takers SAT Critical Reading Avg. Score  \\\n",
       "0                       29                             355   \n",
       "1                       91                             383   \n",
       "2                       70                             377   \n",
       "3                        7                             414   \n",
       "4                       44                             390   \n",
       "..                     ...                             ...   \n",
       "488                    403                             391   \n",
       "489                     85                             406   \n",
       "490                     54                             413   \n",
       "491                    264                             407   \n",
       "492                     65                             364   \n",
       "\n",
       "    SAT Math Avg. Score SAT Writing Avg. Score SAT Critical Readng Avg. Score  \\\n",
       "0                   404                    363                            355   \n",
       "1                   423                    366                            383   \n",
       "2                   402                    370                            377   \n",
       "3                   401                    359                            414   \n",
       "4                   433                    384                            390   \n",
       "..                  ...                    ...                            ...   \n",
       "488                 409                    392                            391   \n",
       "489                 391                    392                            406   \n",
       "490                 399                    398                            413   \n",
       "491                 440                    393                            407   \n",
       "492                 378                    348                            364   \n",
       "\n",
       "     internal_school_id contact_extension pct_students_tested  \\\n",
       "0                218160              x345                 78%   \n",
       "1                268547              x234                 NaN   \n",
       "2                236446              x123                 NaN   \n",
       "3                427826              x123                 92%   \n",
       "4                672714              x123                 92%   \n",
       "..                  ...               ...                 ...   \n",
       "488              863765               NaN                 92%   \n",
       "489              937579              x234                 NaN   \n",
       "490              296405              x123                 78%   \n",
       "491              892839               NaN                 92%   \n",
       "492              277389              x345                 92%   \n",
       "\n",
       "     academic_tier_rating  \n",
       "0                     2.0  \n",
       "1                     3.0  \n",
       "2                     3.0  \n",
       "3                     4.0  \n",
       "4                     2.0  \n",
       "..                    ...  \n",
       "488                   1.0  \n",
       "489                   NaN  \n",
       "490                   2.0  \n",
       "491                   2.0  \n",
       "492                   NaN  \n",
       "\n",
       "[493 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open the CSV and review its structure\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/Users/svitlanakovalivska/onboarding_weebet/_onboarding_data-1/daily_tasks/day_4/day_4_datasets/sat-results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493 entries, 0 to 492\n",
      "Data columns (total 11 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              493 non-null    object \n",
      " 1   SCHOOL NAME                      493 non-null    object \n",
      " 2   Num of SAT Test Takers           493 non-null    object \n",
      " 3   SAT Critical Reading Avg. Score  493 non-null    object \n",
      " 4   SAT Math Avg. Score              493 non-null    object \n",
      " 5   SAT Writing Avg. Score           493 non-null    object \n",
      " 6   SAT Critical Readng Avg. Score   493 non-null    object \n",
      " 7   internal_school_id               493 non-null    int64  \n",
      " 8   contact_extension                388 non-null    object \n",
      " 9   pct_students_tested              376 non-null    object \n",
      " 10  academic_tier_rating             402 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 42.5+ KB\n",
      "Number of duplicate rows: 15\n",
      "Unique values in each column:\n",
      "DBN: 478\n",
      "SCHOOL NAME: 478\n",
      "Num of SAT Test Takers: 175\n",
      "SAT Critical Reading Avg. Score: 164\n",
      "SAT Math Avg. Score: 177\n",
      "SAT Writing Avg. Score: 163\n",
      "SAT Critical Readng Avg. Score: 164\n",
      "internal_school_id: 478\n",
      "contact_extension: 3\n",
      "pct_students_tested: 3\n",
      "academic_tier_rating: 4\n",
      "Missing values in each column:\n",
      "DBN                                  0\n",
      "SCHOOL NAME                          0\n",
      "Num of SAT Test Takers               0\n",
      "SAT Critical Reading Avg. Score      0\n",
      "SAT Math Avg. Score                  0\n",
      "SAT Writing Avg. Score               0\n",
      "SAT Critical Readng Avg. Score       0\n",
      "internal_school_id                   0\n",
      "contact_extension                  105\n",
      "pct_students_tested                117\n",
      "academic_tier_rating                91\n",
      "dtype: int64\n",
      "Descriptive statistics for internal_school_id:\n",
      "count       493.000000\n",
      "mean     562172.943205\n",
      "std      262138.627055\n",
      "min      101855.000000\n",
      "25%      332013.000000\n",
      "50%      587220.000000\n",
      "75%      782993.000000\n",
      "max      999398.000000\n",
      "Name: internal_school_id, dtype: float64\n",
      "\n",
      "\n",
      "Descriptive statistics for academic_tier_rating:\n",
      "count    402.000000\n",
      "mean       2.564677\n",
      "std        1.126443\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        4.000000\n",
      "max        4.000000\n",
      "Name: academic_tier_rating, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identify which columns are useful and which are synthetic or dirty\n",
    "\n",
    "# Check for null values and data types\n",
    "df.info()\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Check for unique values in each column\n",
    "unique_values = {col: df[col].nunique() for col in df.columns}\n",
    "print(\"Unique values in each column:\")\n",
    "for col, count in unique_values.items():\n",
    "    print(f\"{col}: {count}\")        \n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Check for outliers in numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_cols:\n",
    "    print(f\"Descriptive statistics for {col}:\")\n",
    "    print(df[col].describe())\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in each column:\n",
      "DBN                                 0.000000\n",
      "SCHOOL NAME                         0.000000\n",
      "Num of SAT Test Takers              0.000000\n",
      "SAT Critical Reading Avg. Score     0.000000\n",
      "SAT Math Avg. Score                 0.000000\n",
      "SAT Writing Avg. Score              0.000000\n",
      "SAT Critical Readng Avg. Score      0.000000\n",
      "internal_school_id                  0.000000\n",
      "contact_extension                  21.298174\n",
      "pct_students_tested                23.732252\n",
      "academic_tier_rating               18.458418\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Percentage of nul-values in the dataset\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"Percentage of missing values in each column:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the DataFrame: Index(['DBN', 'SCHOOL NAME', 'Num of SAT Test Takers',\n",
      "       'SAT Critical Reading Avg. Score', 'SAT Math Avg. Score',\n",
      "       'SAT Writing Avg. Score', 'SAT Critical Readng Avg. Score',\n",
      "       'internal_school_id', 'contact_extension', 'pct_students_tested',\n",
      "       'academic_tier_rating'],\n",
      "      dtype='object') \n",
      "No duplicated column names found.\n",
      "The columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' are identical.\n"
     ]
    }
   ],
   "source": [
    "#Column names review\n",
    "print(f\"Column names in the DataFrame: {df.columns} \")\n",
    "\n",
    "\n",
    "#Check the duplicated column names  \n",
    "duplicated_columns = df.columns[df.columns.duplicated()].tolist()\n",
    "if duplicated_columns:\n",
    "    print(\"Duplicated column names found:\")\n",
    "    print(duplicated_columns)\n",
    "else:\n",
    "    print(\"No duplicated column names found.\")  \n",
    "\n",
    "#Check if 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' columns are identical\n",
    "if 'SAT Critical Reading Avg. Score' in df.columns and 'SAT Critical Readng Avg. Score' in df.columns:\n",
    "    if df['SAT Critical Reading Avg. Score'].equals(df['SAT Critical Readng Avg. Score']):\n",
    "        print(\"The columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' are identical.\")\n",
    "    else:\n",
    "        print(\"The columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' are different.\")\n",
    "else:\n",
    "    print(\"One or both of the columns 'SAT Critical Reading Avg. Score' and 'SAT Critical Readng Avg. Score' do not exist in the DataFrame.\")   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a description of the key columns in the NYC SAT results dataset. This reference will help you understand what each field represents as you clean, explore, and analyze the data.\n",
    "\n",
    "Column Name\tDescription\n",
    "DBN\tDistrict Borough Number, a unique code identifying each school (e.g., 01M292)\n",
    "School Name\tThe full official name of the high school\n",
    "Num of SAT Test Takers\tNumber of students from the school who took the SAT exam\n",
    "SAT Critical Reading Avg. Score\tAverage score achieved in the Critical Reading section (valid: 200‚Äì800)\n",
    "SAT Math Avg. Score\tAverage score achieved in the Math section (valid: 200‚Äì800)\n",
    "SAT Writing Avg. Score\tAverage score achieved in the Writing section (valid: 200‚Äì800)\n",
    "SAT Critical Readng Avg. Score\tDuplicate of Critical Reading score with a typo in the column name\n",
    "internal_school_id\tpotentially school ID,generated by system (?)\n",
    "contact_extension\tphone extension (e.g., \"x234\") ‚Äî uncheked\n",
    "pct_students_tested\tPercentage of students tested (as string, e.g., \"85%\", \"N/A\")\n",
    "academic_tier_rating\tperformance tier (scale 1‚Äì4), may contain nulls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Num of SAT Test Takers' has object type with unique values:\n",
      "['29' '91' '70' '7' '44' '112' '159' '18' '130' '16' '62' '53' '58' '85'\n",
      " '48' '76' '50' '40' '69' '42' '60' '92' 's' '79' '263' '54' '94' '104'\n",
      " '114' '66' '103' '127' '144' '336' '84' '95' '59' '72' '49' '151' '832'\n",
      " '167' '25' '81' '264' '131' '73' '14' '78' '26' '77' '56' '30' '33' '121'\n",
      " '9' '335' '36' '83' '154' '191' '270' '61' '27' '41' '12' '32' '261'\n",
      " '531' '75' '35' '111' '43' '375' '51' '31' '20' '214' '101' '55' '63'\n",
      " '24' '228' '65' '34' '64' '28' '47' '52' '67' '39' '415' '6' '68' '80'\n",
      " '74' '38' '113' '86' '57' '443' '731' '109' '99' '10' '46' '97' '189'\n",
      " '37' '1277' '90' '105' '8' '13' '89' '185' '102' '134' '142' '141' '71'\n",
      " '165' '259' '17' '182' '456' '238' '694' '385' '475' '727' '448' '119'\n",
      " '824' '518' '236' '11' '155' '320' '241' '138' '396' '45' '558' '347'\n",
      " '278' '888' '934' '334' '708' '175' '87' '93' '404' '403' '194' '762'\n",
      " '462' '422' '98' '395' '392' '174' '148' '143' '135' '137' '107' '391'\n",
      " '271' '807' '535' '227' '88' '23']\n",
      "\n",
      "\n",
      "Column 'SAT Critical Reading Avg. Score' has object type with unique values:\n",
      "['355' '383' '377' '414' '390' '332' '522' '417' '624' '395' '409' '394'\n",
      " '374' '423' '404' '353' '375' '403' '408' '373' '391' '473' 's' '319'\n",
      " '465' '492' '509' '496' '537' '517' '468' '572' '528' '429' '416' '356'\n",
      " '441' '378' '376' '679' '443' '370' '469' '407' '336' '389' '412' '368'\n",
      " '405' '498' '527' '350' '345' '458' '426' '399' '444' '406' '384' '371'\n",
      " '577' '566' '396' '433' '401' '354' '461' '432' '369' '358' '357' '413'\n",
      " '360' '605' '362' '380' '365' '363' '400' '430' '339' '364' '379' '310'\n",
      " '361' '351' '420' '367' '387' '398' '337' '402' '366' '324' '372' '411'\n",
      " '393' '459' '386' '382' '315' '314' '438' '304' '300' '392' '343' '419'\n",
      " '632' '348' '636' '381' '431' '388' '347' '321' '342' '352' '439' '587'\n",
      " '305' '435' '471' '586' '397' '359' '287' '338' '457' '418' '385' '476'\n",
      " '425' '313' '410' '341' '279' '326' '478' '436' '524' '456' '349' '311'\n",
      " '317' '545' '445' '455' '621' '480' '462' '499' '452' '513' '612' '504'\n",
      " '323' '487' '472' '424' '437' '466' '635' '428']\n",
      "\n",
      "\n",
      "Column 'SAT Math Avg. Score' has object type with unique values:\n",
      "['404' '423' '402' '401' '433' '557' '574' '418' '604' '400' '393' '384'\n",
      " '375' '438' '449' '358' '388' '392' '390' '370' '391' '483' 's' '512'\n",
      " '493' '465' '490' '563' '590' '533' '492' '594' '553' '399' '426' '357'\n",
      " '473' '365' '416' '460' '387' '735' '489' '349' '472' '440' '425' '378'\n",
      " '395' '371' '581' '436' '508' '337' '517' '403' '379' '382' '441' '424'\n",
      " '850' '575' '564' '398' '369' '506' '514' '421' '446' '351' '318' '366'\n",
      " '353' '360' '474' '361' '654' '376' '380' '422' '456' '364' '324' '359'\n",
      " '394' '396' '356' '411' '381' '368' '386' '385' '373' '355' '464' '367'\n",
      " '480' '363' '339' '312' '419' '315' '455' '412' '-10' '406' '333' '408'\n",
      " '350' '420' '688' '362' '435' '648' '471' '397' '372' '344' '432' '323'\n",
      " '346' '374' '417' '659' '383' '443' '499' '584' '410' '377' '335' '415'\n",
      " '341' '999' '342' '462' '481' '413' '320' '322' '478' '486' '477' '427'\n",
      " '437' '496' '468' '414' '519' '475' '561' '409' '338' '454' '429' '568'\n",
      " '447' '498' '463' '451' '651' '458' '545' '539' '523' '434' '537' '491'\n",
      " '445' '452' '497' '660' '1100' '488' '682' '317' '444']\n",
      "\n",
      "\n",
      "Column 'SAT Writing Avg. Score' has object type with unique values:\n",
      "['363' '366' '370' '359' '384' '316' '525' '411' '628' '387' '392' '378'\n",
      " '362' '432' '416' '340' '385' '405' '390' '394' '479' 's' '357' '461'\n",
      " '467' '523' '518' '550' '515' '459' '592' '533' '381' '428' '391' '349'\n",
      " '458' '368' '388' '360' '682' '442' '351' '475' '393' '400' '420' '344'\n",
      " '382' '335' '431' '352' '477' '512' '345' '343' '403' '429' '426' '376'\n",
      " '430' '408' '374' '358' '577' '402' '361' '373' '455' '395' '448' '333'\n",
      " '398' '342' '364' '404' '355' '588' '367' '399' '346' '423' '326' '348'\n",
      " '311' '371' '383' '407' '389' '375' '350' '413' '365' '356' '377' '415'\n",
      " '457' '297' '339' '379' '369' '440' '302' '301' '330' '372' '410' '427'\n",
      " '649' '414' '354' '317' '636' '433' '353' '419' '341' '298' '312' '418'\n",
      " '587' '570' '396' '380' '300' '425' '334' '291' '441' '386' '286' '424'\n",
      " '314' '435' '476' '439' '542' '331' '332' '421' '329' '406' '443' '318'\n",
      " '481' '638' '489' '464' '401' '496' '454' '502' '596' '412' '494' '491'\n",
      " '544' '450' '466' '417' '470' '397' '422']\n",
      "\n",
      "\n",
      "Column 'SAT Critical Readng Avg. Score' has object type with unique values:\n",
      "['355' '383' '377' '414' '390' '332' '522' '417' '624' '395' '409' '394'\n",
      " '374' '423' '404' '353' '375' '403' '408' '373' '391' '473' 's' '319'\n",
      " '465' '492' '509' '496' '537' '517' '468' '572' '528' '429' '416' '356'\n",
      " '441' '378' '376' '679' '443' '370' '469' '407' '336' '389' '412' '368'\n",
      " '405' '498' '527' '350' '345' '458' '426' '399' '444' '406' '384' '371'\n",
      " '577' '566' '396' '433' '401' '354' '461' '432' '369' '358' '357' '413'\n",
      " '360' '605' '362' '380' '365' '363' '400' '430' '339' '364' '379' '310'\n",
      " '361' '351' '420' '367' '387' '398' '337' '402' '366' '324' '372' '411'\n",
      " '393' '459' '386' '382' '315' '314' '438' '304' '300' '392' '343' '419'\n",
      " '632' '348' '636' '381' '431' '388' '347' '321' '342' '352' '439' '587'\n",
      " '305' '435' '471' '586' '397' '359' '287' '338' '457' '418' '385' '476'\n",
      " '425' '313' '410' '341' '279' '326' '478' '436' '524' '456' '349' '311'\n",
      " '317' '545' '445' '455' '621' '480' '462' '499' '452' '513' '612' '504'\n",
      " '323' '487' '472' '424' '437' '466' '635' '428']\n",
      "\n",
      "\n",
      "Column 'contact_extension' has object type with unique values:\n",
      "['x345' 'x234' 'x123' nan]\n",
      "\n",
      "\n",
      "Column 'pct_students_tested' has object type with unique values:\n",
      "['78%' nan '92%' '85%']\n",
      "\n",
      "\n",
      "Percentage columns found:\n",
      "pct_students_tested: ['78%' nan '92%' '85%']\n"
     ]
    }
   ],
   "source": [
    "# Check why data columns have the object type - which objects are inside (check only the columns where number of unique values is less the the number of rows)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and df[col].nunique() < len(df):\n",
    "        print(f\"Column '{col}' has object type with unique values:\")\n",
    "        print(df[col].unique())\n",
    "        print(\"\\n\")\n",
    "# Check for percentage columns\n",
    "percentage_columns = [col for col in df.columns if df[col].dtype == 'object' and df[col].str.contains('%').any()]\n",
    "if percentage_columns:\n",
    "    print(\"Percentage columns found:\")\n",
    "    for col in percentage_columns:\n",
    "        print(f\"{col}: {df[col].unique()}\")\n",
    "else:\n",
    "    print(\"No percentage columns found.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'SCHOOL NAME' has 7 's' values (1.46%)\n",
      "Column 'Num of SAT Test Takers' has 57 's' values (11.92%)\n",
      "Column 'SAT Critical Reading Avg. Score' has 57 's' values (11.92%)\n",
      "Column 'SAT Math Avg. Score' has 57 's' values (11.92%)\n",
      "Column 'SAT Writing Avg. Score' has 57 's' values (11.92%)\n",
      "Column 'SAT Critical Readng Avg. Score' has 57 's' values (11.92%)\n",
      "Total 's' values across all columns: 292\n"
     ]
    }
   ],
   "source": [
    "#Count the nomber of rows with the s-values in the each column, and percentage od these number of rows for each column  \n",
    "s_count = 0\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        s_mask = df[col].str.contains('s', na=False)\n",
    "        if s_mask.any():\n",
    "            count = s_mask.sum()\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"Column '{col}' has {count} 's' values ({percentage:.2f}%)\")\n",
    "            s_count += count    \n",
    "# Print total count of 's' values\n",
    "print(f\"Total 's' values across all columns: {s_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! The percentage of rows with s-values is greater than 5, so we can't just delete them, we need to think about how to deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of the Step 1:\n",
    "\n",
    "Columns such as SAT Critical Readng Avg. Score (Duplicate of Critical Reading score with a typo), internal_school_id (no needed for SAT), contact_extension (contact info is no needed, too much missing values) are probably not useful for the SAT dataset and should be removed.  \n",
    "\n",
    "Other column names should be cleaned up and renamed so that they have the same format and the correct data type (including %-removal and dealing with the missing data and s-values (change on NaN first - in order to keep in the dataset all rows).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean the Data Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fixed column names:\n",
      "1. 'dbn'\n",
      "2. 'school_name'\n",
      "3. 'num_of_sat_test_takers'\n",
      "4. 'sat_critical_reading_avg_score'\n",
      "5. 'sat_math_avg_score'\n",
      "6. 'sat_writing_avg_score'\n",
      "7. 'internal_school_id'\n",
      "8. 'contact_extension'\n",
      "9. 'pct_students_tested'\n",
      "10. 'academic_tier_rating'\n",
      "\n",
      " CORRECTED DATASET:\n",
      "Shape: (478, 10)\n",
      "Columns: ['dbn', 'school_name', 'num_of_sat_test_takers', 'sat_critical_reading_avg_score', 'sat_math_avg_score', 'sat_writing_avg_score', 'internal_school_id', 'contact_extension', 'pct_students_tested', 'academic_tier_rating']\n",
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbn</th>\n",
       "      <th>school_name</th>\n",
       "      <th>num_of_sat_test_takers</th>\n",
       "      <th>sat_critical_reading_avg_score</th>\n",
       "      <th>sat_math_avg_score</th>\n",
       "      <th>sat_writing_avg_score</th>\n",
       "      <th>internal_school_id</th>\n",
       "      <th>contact_extension</th>\n",
       "      <th>pct_students_tested</th>\n",
       "      <th>academic_tier_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>29</td>\n",
       "      <td>355</td>\n",
       "      <td>404</td>\n",
       "      <td>363</td>\n",
       "      <td>218160</td>\n",
       "      <td>x345</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "      <td>423</td>\n",
       "      <td>366</td>\n",
       "      <td>268547</td>\n",
       "      <td>x234</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>70</td>\n",
       "      <td>377</td>\n",
       "      <td>402</td>\n",
       "      <td>370</td>\n",
       "      <td>236446</td>\n",
       "      <td>x123</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dbn                                    school_name  \\\n",
       "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
       "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
       "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
       "\n",
       "   num_of_sat_test_takers  sat_critical_reading_avg_score  sat_math_avg_score  \\\n",
       "0                      29                             355                 404   \n",
       "1                      91                             383                 423   \n",
       "2                      70                             377                 402   \n",
       "\n",
       "   sat_writing_avg_score  internal_school_id contact_extension  \\\n",
       "0                    363              218160              x345   \n",
       "1                    366              268547              x234   \n",
       "2                    370              236446              x123   \n",
       "\n",
       "   pct_students_tested  academic_tier_rating  \n",
       "0                   78                     2  \n",
       "1                    0                     3  \n",
       "2                    0                     3  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Data cleaning strategy\n",
    "\n",
    "# Fix the column naming issue\n",
    "df_cleaned_fixed = df.copy()\n",
    "\n",
    "# 1. Remove the problematic duplicate column \n",
    "if 'SAT Critical Readng Avg. Score' in df_cleaned_fixed.columns:\n",
    "    df_cleaned_fixed = df_cleaned_fixed.drop(columns=['SAT Critical Readng Avg. Score'])\n",
    "\n",
    "\n",
    "\n",
    "# 2.Properly clean column names\n",
    "df_cleaned_fixed.columns = (df_cleaned_fixed.columns\n",
    "                           .str.strip()                    # Remove spaces\n",
    "                           .str.replace(' ', '_')          # Replace spaces with underscores\n",
    "                           .str.replace('.', '')           # Remove periods\n",
    "                           .str.lower())                   # Convert to lowercase\n",
    "\n",
    "print(f\"\\n Fixed column names:\")\n",
    "for i, col in enumerate(df_cleaned_fixed.columns, 1):\n",
    "    print(f\"{i}. '{col}'\")\n",
    "\n",
    "# 3. Convert data types properly into integer values (not float)\n",
    "# Convert numerical columns to numeric types, handling errors and replacing 's' with None\n",
    "\n",
    "df_cleaned_fixed['num_of_sat_test_takers'] = pd.to_numeric(df_cleaned_fixed['num_of_sat_test_takers'].replace('s', None), errors='coerce')\n",
    "df_cleaned_fixed['sat_critical_reading_avg_score'] = pd.to_numeric(df_cleaned_fixed['sat_critical_reading_avg_score'].replace('s', None), errors='coerce')\n",
    "df_cleaned_fixed['sat_math_avg_score'] = pd.to_numeric(df_cleaned_fixed['sat_math_avg_score'].replace('s', None), errors='coerce')\n",
    "df_cleaned_fixed['sat_writing_avg_score'] = pd.to_numeric(df_cleaned_fixed['sat_writing_avg_score'].replace('s', None), errors='coerce')\n",
    "\n",
    "for col in df_cleaned_fixed.select_dtypes(include=['float64']).columns:\n",
    "    df_cleaned_fixed[col] = df_cleaned_fixed[col].fillna(0).astype(int) \n",
    "\n",
    "# 4.Fix percentage column\n",
    "if 'pct_students_tested' in df_cleaned_fixed.columns:\n",
    "    df_cleaned_fixed['pct_students_tested'] = df_cleaned_fixed['pct_students_tested'].str.replace('%', '').astype(float)\n",
    "\n",
    "#convert float into integer\n",
    "for col in df_cleaned_fixed.select_dtypes(include=['float64']).columns:\n",
    "    df_cleaned_fixed[col] = df_cleaned_fixed[col].fillna(0).astype(int)\n",
    "    \n",
    "print(f\"\\n CORRECTED DATASET:\")\n",
    "print(f\"Shape: {df_cleaned_fixed.shape}\")\n",
    "print(f\"Columns: {list(df_cleaned_fixed.columns)}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "df_cleaned_fixed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Removed 0 duplicate rows\n",
      "   Rows: 478 ‚Üí 478\n",
      "\n",
      " CLEANING RESULTS\n",
      " Final dataset shape: (478, 10)\n",
      "Data types after cleaning:\n",
      "dbn                               object\n",
      "school_name                       object\n",
      "num_of_sat_test_takers             int64\n",
      "sat_critical_reading_avg_score     int64\n",
      "sat_math_avg_score                 int64\n",
      "sat_writing_avg_score              int64\n",
      "internal_school_id                 int64\n",
      "contact_extension                 object\n",
      "pct_students_tested                int64\n",
      "academic_tier_rating               int64\n",
      "dtype: object\n",
      "\n",
      " Missing values after cleaning:\n",
      "contact_extension    100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the cleaned data\n",
    "\n",
    "# Start with a copy of the original data\n",
    "df_cleaned = df_cleaned_fixed.copy()\n",
    "\n",
    "# 1. Check duplicate rows ones more\n",
    "initial_rows = len(df_cleaned)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "duplicates_removed = initial_rows - len(df_cleaned)\n",
    "print(f\"   Removed {duplicates_removed} duplicate rows\")\n",
    "print(f\"   Rows: {initial_rows} ‚Üí {len(df_cleaned)}\")\n",
    "\n",
    "\n",
    "print(\"\\n CLEANING RESULTS\")\n",
    "print(f\" Final dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"Data types after cleaning:\")\n",
    "print(df_cleaned.dtypes)\n",
    "\n",
    "print(f\"\\n Missing values after cleaning:\")\n",
    "missing_after = df_cleaned.isnull().sum()\n",
    "print(missing_after[missing_after > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SAT SCORE RANGE VALIDATION:\n",
      "sat_critical_reading_avg_score:\n",
      "Range: 0 - 679 Invalid range\n",
      "Mean: 353.1\n",
      "sat_math_avg_score:\n",
      "Range: -10 - 1100 Invalid range\n",
      "Mean: 368.3\n",
      "sat_writing_avg_score:\n",
      "Range: 0 - 682 Invalid range\n",
      "Mean: 347.0\n",
      "\n",
      " PERCENTAGE VALIDATION:\n",
      "pct_students_tested: 0% - 92% Valid percentage range\n",
      "\n",
      " REMAINING DATA QUALITY CHECKS:\n",
      "Duplicate rows: 0\n",
      "Unique schools (DBN): 478\n",
      "\n",
      " FINAL DATASET READY FOR DATABASE!\n",
      "Dataset shape: (478, 10)\n",
      "All numerical columns properly typed\n",
      "No duplicate rows\n",
      "Valid SAT score ranges (200-800)\n",
      "Valid percentage ranges (0-100%)\n",
      "Missing values properly handled as NaN\n",
      "\n",
      " CLEANED DATA SUMMARY:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_sat_test_takers</th>\n",
       "      <th>sat_critical_reading_avg_score</th>\n",
       "      <th>sat_math_avg_score</th>\n",
       "      <th>sat_writing_avg_score</th>\n",
       "      <th>internal_school_id</th>\n",
       "      <th>pct_students_tested</th>\n",
       "      <th>academic_tier_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>478.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>97.165272</td>\n",
       "      <td>353.050209</td>\n",
       "      <td>368.307531</td>\n",
       "      <td>347.004184</td>\n",
       "      <td>560082.717573</td>\n",
       "      <td>64.242678</td>\n",
       "      <td>2.115063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>150.270071</td>\n",
       "      <td>140.542605</td>\n",
       "      <td>158.920585</td>\n",
       "      <td>139.155359</td>\n",
       "      <td>259637.064755</td>\n",
       "      <td>36.532971</td>\n",
       "      <td>1.423575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101855.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>358.250000</td>\n",
       "      <td>362.250000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>337012.500000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.500000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>387.500000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>581301.500000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>411.750000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>778312.750000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1277.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>999398.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_of_sat_test_takers  sat_critical_reading_avg_score  \\\n",
       "count              478.000000                      478.000000   \n",
       "mean                97.165272                      353.050209   \n",
       "std                150.270071                      140.542605   \n",
       "min                  0.000000                        0.000000   \n",
       "25%                 30.000000                      358.250000   \n",
       "50%                 56.500000                      384.000000   \n",
       "75%                 89.000000                      411.750000   \n",
       "max               1277.000000                      679.000000   \n",
       "\n",
       "       sat_math_avg_score  sat_writing_avg_score  internal_school_id  \\\n",
       "count          478.000000             478.000000          478.000000   \n",
       "mean           368.307531             347.004184       560082.717573   \n",
       "std            158.920585             139.155359       259637.064755   \n",
       "min            -10.000000               0.000000       101855.000000   \n",
       "25%            362.250000             351.000000       337012.500000   \n",
       "50%            387.500000             376.000000       581301.500000   \n",
       "75%            432.000000             403.000000       778312.750000   \n",
       "max           1100.000000             682.000000       999398.000000   \n",
       "\n",
       "       pct_students_tested  academic_tier_rating  \n",
       "count           478.000000            478.000000  \n",
       "mean             64.242678              2.115063  \n",
       "std              36.532971              1.423575  \n",
       "min               0.000000              0.000000  \n",
       "25%              78.000000              1.000000  \n",
       "50%              78.000000              2.000000  \n",
       "75%              85.000000              3.000000  \n",
       "max              92.000000              4.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anomalies validation\n",
    "\n",
    "\n",
    "# 1. Check SAT score ranges are reasonable\n",
    "print(\"\\n SAT SCORE RANGE VALIDATION:\")\n",
    "sat_score_cols = ['sat_critical_reading_avg_score', 'sat_math_avg_score', 'sat_writing_avg_score']\n",
    "for col in sat_score_cols:\n",
    "    valid_scores = df_cleaned[col].dropna()\n",
    "    min_score = valid_scores.min()\n",
    "    max_score = valid_scores.max()\n",
    "    mean_score = valid_scores.mean()\n",
    "    \n",
    "    # SAT scores should be between 200-800\n",
    "    if min_score >= 200 and max_score <= 800:\n",
    "        status = \"Valid range\"\n",
    "    else:\n",
    "        status = \"Invalid range\"\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"Range: {min_score:.0f} - {max_score:.0f} {status}\")\n",
    "    print(f\"Mean: {mean_score:.1f}\")\n",
    "\n",
    "# 2. Check percentage values\n",
    "print(\"\\n PERCENTAGE VALIDATION:\")\n",
    "if 'pct_students_tested' in df_cleaned.columns:\n",
    "    pct_valid = df_cleaned['pct_students_tested'].dropna()\n",
    "    pct_min = pct_valid.min()\n",
    "    pct_max = pct_valid.max()\n",
    "    \n",
    "    if pct_min >= 0 and pct_max <= 100:\n",
    "        status = \"Valid percentage range\"\n",
    "    else:\n",
    "        status = \"Invalid percentage range\"\n",
    "    \n",
    "    print(f\"pct_students_tested: {pct_min:.0f}% - {pct_max:.0f}% {status}\")\n",
    "\n",
    "# 3. Check for remaining data quality issues\n",
    "print(\"\\n REMAINING DATA QUALITY CHECKS:\")\n",
    "print(f\"Duplicate rows: {df_cleaned.duplicated().sum()}\")\n",
    "print(f\"Unique schools (DBN): {df_cleaned['dbn'].nunique()}\")\n",
    "\n",
    "# 4. Summary statistics for cleaned data\n",
    "\n",
    "print(\"\\n FINAL DATASET READY FOR DATABASE!\")\n",
    "print(f\"Dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"All numerical columns properly typed\")\n",
    "print(f\"No duplicate rows\")\n",
    "print(f\"Valid SAT score ranges (200-800)\")\n",
    "print(f\"Valid percentage ranges (0-100%)\")\n",
    "print(f\"Missing values properly handled as NaN\")\n",
    "print(\"\\n CLEANED DATA SUMMARY:\")\n",
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sat_critical_reading_avg_score out of range: 57 (11.92%)\n",
      "   sat_math_avg_score out of range: 62 (12.97%)\n",
      "   sat_writing_avg_score out of range: 57 (11.92%)\n",
      "\n",
      "REMAINING ANOMALIES CHECKS\n",
      "Remaining duplicate rows: 0\n",
      "Unique schools (DBN): 416\n",
      "   pct_students_tested: 0% - 92%  Valid percentage range\n",
      "\n",
      " FINAL VALIDATION CHECKS AFTER CLEANING:\n",
      "Dataset shape: (416, 10)\n",
      "Data types after cleaning:\n",
      "dbn                               object\n",
      "school_name                       object\n",
      "num_of_sat_test_takers             int64\n",
      "sat_critical_reading_avg_score     int64\n",
      "sat_math_avg_score                 int64\n",
      "sat_writing_avg_score              int64\n",
      "internal_school_id                 int64\n",
      "contact_extension                 object\n",
      "pct_students_tested                int64\n",
      "academic_tier_rating               int64\n",
      "dtype: object\n",
      "\n",
      " Missing values after cleaning:\n",
      "contact_extension    85\n",
      "dtype: int64\n",
      "All numerical columns properly typed\n",
      "No duplicate rows\n",
      "Valid SAT score ranges (200-800)\n",
      "Valid percentage ranges (0-100%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_sat_test_takers</th>\n",
       "      <th>sat_critical_reading_avg_score</th>\n",
       "      <th>sat_math_avg_score</th>\n",
       "      <th>sat_writing_avg_score</th>\n",
       "      <th>internal_school_id</th>\n",
       "      <th>pct_students_tested</th>\n",
       "      <th>academic_tier_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>110.769231</td>\n",
       "      <td>401.067308</td>\n",
       "      <td>413.733173</td>\n",
       "      <td>394.175481</td>\n",
       "      <td>572765.245192</td>\n",
       "      <td>63.718750</td>\n",
       "      <td>2.163462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>156.354878</td>\n",
       "      <td>57.017818</td>\n",
       "      <td>64.945638</td>\n",
       "      <td>58.915340</td>\n",
       "      <td>257828.614058</td>\n",
       "      <td>36.929242</td>\n",
       "      <td>1.397834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>102816.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>353089.500000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>381.500000</td>\n",
       "      <td>602509.500000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>95.500000</td>\n",
       "      <td>416.250000</td>\n",
       "      <td>437.250000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>786460.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1277.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>999398.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_of_sat_test_takers  sat_critical_reading_avg_score  \\\n",
       "count              416.000000                      416.000000   \n",
       "mean               110.769231                      401.067308   \n",
       "std                156.354878                       57.017818   \n",
       "min                  6.000000                      279.000000   \n",
       "25%                 41.000000                      368.000000   \n",
       "50%                 62.000000                      391.000000   \n",
       "75%                 95.500000                      416.250000   \n",
       "max               1277.000000                      679.000000   \n",
       "\n",
       "       sat_math_avg_score  sat_writing_avg_score  internal_school_id  \\\n",
       "count          416.000000             416.000000          416.000000   \n",
       "mean           413.733173             394.175481       572765.245192   \n",
       "std             64.945638              58.915340       257828.614058   \n",
       "min            312.000000             286.000000       102816.000000   \n",
       "25%            372.000000             360.000000       353089.500000   \n",
       "50%            395.000000             381.500000       602509.500000   \n",
       "75%            437.250000             411.000000       786460.000000   \n",
       "max            735.000000             682.000000       999398.000000   \n",
       "\n",
       "       pct_students_tested  academic_tier_rating  \n",
       "count           416.000000            416.000000  \n",
       "mean             63.718750              2.163462  \n",
       "std              36.929242              1.397834  \n",
       "min               0.000000              0.000000  \n",
       "25%              78.000000              1.000000  \n",
       "50%              78.000000              2.000000  \n",
       "75%              85.000000              3.000000  \n",
       "max              92.000000              4.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the anomalies (out of range, with the invalid range)in numbers and percentages for each sat_score_cols\n",
    "for col in sat_score_cols:\n",
    "    out_of_range = df_cleaned[(df_cleaned[col] < 200) | (df_cleaned[col] > 800)]\n",
    "    count_out_of_range = len(out_of_range)\n",
    "    percentage_out_of_range = (count_out_of_range / len(df_cleaned)) * 100\n",
    "    \n",
    "    print(f\"   {col} out of range: {count_out_of_range} ({percentage_out_of_range:.2f}%)\")\n",
    "\n",
    "# Drop the rows with out of range SAT scores\n",
    "for col in sat_score_cols:\n",
    "    df_cleaned = df_cleaned[(df_cleaned[col] >= 200) & (df_cleaned[col] <= 800)]    \n",
    "\n",
    "# Check for remaining anomalies after cleaning\n",
    "print(\"\\nREMAINING ANOMALIES CHECKS\")\n",
    "print(f\"Remaining duplicate rows: {df_cleaned.duplicated().sum()}\")\n",
    "print(f\"Unique schools (DBN): {df_cleaned['dbn'].nunique()}\")\n",
    "# Check for percentage values again\n",
    "if 'pct_students_tested' in df_cleaned.columns:\n",
    "    pct_valid = df_cleaned['pct_students_tested'].dropna()\n",
    "    pct_min = pct_valid.min()\n",
    "    pct_max = pct_valid.max()\n",
    "    \n",
    "    if pct_min >= 0 and pct_max <= 100:\n",
    "        status = \" Valid percentage range\"\n",
    "    else:\n",
    "        status = \" Invalid percentage range\"\n",
    "    \n",
    "    print(f\"   pct_students_tested: {pct_min:.0f}% - {pct_max:.0f}% {status}\")\n",
    "\n",
    "\n",
    "# Final validation checks\n",
    "\n",
    "print(\"\\n FINAL VALIDATION CHECKS AFTER CLEANING:\")\n",
    "print(f\"Dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"Data types after cleaning:\")\n",
    "print(df_cleaned.dtypes)\n",
    "print(f\"\\n Missing values after cleaning:\")\n",
    "missing_after = df_cleaned.isnull().sum()\n",
    "print(missing_after[missing_after > 0]) \n",
    "\n",
    "\n",
    "print(f\"All numerical columns properly typed\")\n",
    "print(f\"No duplicate rows\")\n",
    "print(f\"Valid SAT score ranges (200-800)\")\n",
    "print(f\"Valid percentage ranges (0-100%)\")\n",
    "\n",
    "\n",
    "df_cleaned.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANED DATASET PREVIEW:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbn</th>\n",
       "      <th>school_name</th>\n",
       "      <th>num_of_sat_test_takers</th>\n",
       "      <th>sat_critical_reading_avg_score</th>\n",
       "      <th>sat_math_avg_score</th>\n",
       "      <th>sat_writing_avg_score</th>\n",
       "      <th>internal_school_id</th>\n",
       "      <th>contact_extension</th>\n",
       "      <th>pct_students_tested</th>\n",
       "      <th>academic_tier_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>29</td>\n",
       "      <td>355</td>\n",
       "      <td>404</td>\n",
       "      <td>363</td>\n",
       "      <td>218160</td>\n",
       "      <td>x345</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "      <td>423</td>\n",
       "      <td>366</td>\n",
       "      <td>268547</td>\n",
       "      <td>x234</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>70</td>\n",
       "      <td>377</td>\n",
       "      <td>402</td>\n",
       "      <td>370</td>\n",
       "      <td>236446</td>\n",
       "      <td>x123</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>FORSYTH SATELLITE ACADEMY</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>427826</td>\n",
       "      <td>x123</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>44</td>\n",
       "      <td>390</td>\n",
       "      <td>433</td>\n",
       "      <td>384</td>\n",
       "      <td>672714</td>\n",
       "      <td>x123</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dbn                                    school_name  \\\n",
       "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
       "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
       "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
       "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
       "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
       "\n",
       "   num_of_sat_test_takers  sat_critical_reading_avg_score  sat_math_avg_score  \\\n",
       "0                      29                             355                 404   \n",
       "1                      91                             383                 423   \n",
       "2                      70                             377                 402   \n",
       "3                       7                             414                 401   \n",
       "4                      44                             390                 433   \n",
       "\n",
       "   sat_writing_avg_score  internal_school_id contact_extension  \\\n",
       "0                    363              218160              x345   \n",
       "1                    366              268547              x234   \n",
       "2                    370              236446              x123   \n",
       "3                    359              427826              x123   \n",
       "4                    384              672714              x123   \n",
       "\n",
       "   pct_students_tested  academic_tier_rating  \n",
       "0                   78                     2  \n",
       "1                    0                     3  \n",
       "2                    0                     3  \n",
       "3                   92                     4  \n",
       "4                   92                     2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the cleaned dataset\n",
    "print(\"CLEANED DATASET PREVIEW:\")\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Design the Schema\n",
    "\n",
    "Now we'll choose which columns to upload to the database and design our table structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns\n",
    "columns_to_drop = ['internal_school_id', 'contact_extension']\n",
    "df_cleaned = df_cleaned.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESIGNING DATABASE SCHEMA\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS sat_results (\n",
      "    dbn VARCHAR(10) PRIMARY KEY,\n",
      "    school_name VARCHAR(255),\n",
      "    num_of_sat_test_takers INTEGER,\n",
      "    sat_critical_reading_avg_score INTEGER,\n",
      "    sat_math_avg_score INTEGER,\n",
      "    sat_writing_avg_score INTEGER,\n",
      "    pct_students_tested INTEGER,\n",
      "    academic_tier_rating INTEGER\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "#  SCHEMA DESIGN FOR DATABASE\n",
    "\n",
    "print(\"DESIGNING DATABASE SCHEMA\\n\")\n",
    "# Define the schema for the cleaned SAT results dataset\n",
    "schema = {\n",
    "    'dbn': 'VARCHAR(10) PRIMARY KEY',\n",
    "    'school_name': 'VARCHAR(255)',\n",
    "    'num_of_sat_test_takers': 'INTEGER',\n",
    "    'sat_critical_reading_avg_score': 'INTEGER',\n",
    "    'sat_math_avg_score': 'INTEGER',\n",
    "    'sat_writing_avg_score': 'INTEGER',\n",
    "    'pct_students_tested': 'INTEGER',\n",
    "    'academic_tier_rating': 'INTEGER'\n",
    "}\n",
    "# Create the SQL CREATE TABLE statement\n",
    "create_table_sql = \"CREATE TABLE IF NOT EXISTS sat_results (\\n\"\n",
    "for column, data_type in schema.items():\n",
    "    create_table_sql += f\"    {column} {data_type},\\n\"\n",
    "create_table_sql = create_table_sql.rstrip(',\\n') + \"\\n);\"      \n",
    "print(create_table_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SCHEMA DIAGRAM:\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ         sat_results          ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ dbn                       VARCHAR(10) PRIMARY KEY ‚îÇ\n",
      "‚îÇ school_name               VARCHAR(255) ‚îÇ\n",
      "‚îÇ num_of_sat_test_takers    INTEGER    ‚îÇ\n",
      "‚îÇ sat_critical_reading_avg_score INTEGER    ‚îÇ\n",
      "‚îÇ sat_math_avg_score        INTEGER    ‚îÇ\n",
      "‚îÇ sat_writing_avg_score     INTEGER    ‚îÇ\n",
      "‚îÇ pct_students_tested       INTEGER    ‚îÇ\n",
      "‚îÇ academic_tier_rating      INTEGER    ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "#Drow the schema diagram \n",
    "\n",
    "# Note: This is a placeholder for the schema diagram. In practice, you would use a tool like pgAdmin or an online ERD tool to visualize the schema.\n",
    "print(\"\\n SCHEMA DIAGRAM:\")\n",
    "print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"‚îÇ         sat_results          ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "for column, data_type in schema.items():\n",
    "    print(f\"‚îÇ {column.ljust(25)} {data_type.ljust(10)} ‚îÇ\")\n",
    "print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write a Python Script to Append Data\n",
    "\n",
    "Upload the cleaned data to the PostgreSQL database using SQLAlchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to table: nyc_schools.svitlana_sat_results\n",
      "Uploading 416 rows with 8 columns\n",
      "SUCCESS: Data uploaded to database!\n",
      "Table created: nyc_schools.svitlana_sat_results\n",
      "VERIFICATION: 416 rows found in database table\n",
      "All rows successfully uploaded!\n"
     ]
    }
   ],
   "source": [
    "# # DATABASE UPLOAD IMPLEMENTATION\n",
    "\n",
    "try:\n",
    "    # Upload cleaned data to database\n",
    "    table_name = 'svitlana_sat_results'  \n",
    "    schema_name = 'nyc_schools'\n",
    "    \n",
    "    print(f\"Uploading data to table: {schema_name}.{table_name}\")\n",
    "    print(f\"Uploading {len(df_cleaned)} rows with {len(df_cleaned.columns)} columns\")\n",
    "    \n",
    "    # Upload to database\n",
    "    df_cleaned.to_sql(\n",
    "        name=table_name,       \n",
    "        con=engine,     \n",
    "        schema=schema_name,\n",
    "        if_exists='replace',    \n",
    "        index=False,           \n",
    "        method='multi'       \n",
    "    )\n",
    "    \n",
    "    print(\"SUCCESS: Data uploaded to database!\")\n",
    "    print(f\"Table created: {schema_name}.{table_name}\")\n",
    "    \n",
    "    # Verify upload by counting rows - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ö–û–î\n",
    "    from sqlalchemy import text\n",
    "    verification_query = text(f\"SELECT COUNT(*) FROM {schema_name}.{table_name}\")\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(verification_query)\n",
    "        row_count = result.fetchone()[0]\n",
    "    \n",
    "    print(f\"VERIFICATION: {row_count} rows found in database table\")\n",
    "    \n",
    "    if row_count == len(df_cleaned):\n",
    "        print(\"All rows successfully uploaded!\")\n",
    "    else:\n",
    "        print(f\" Warning: Expected {len(df_cleaned)} rows, but found {row_count}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" ERROR uploading to database: {str(e)}\")\n",
    "    print(\"Please check your database connection and permissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save the Work\n",
    "\n",
    "Export the cleaned dataset as CSV file as required by the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Cleaned data exported to CSV!\n",
      "File location: /Users/svitlanakovalivska/onboarding_weebet/_onboarding_data-1/daily_tasks/day_4/cleaned_sat_results.csv\n",
      "Exported 416 rows and 8 columns\n",
      "File size: 27,091 bytes\n"
     ]
    }
   ],
   "source": [
    "# EXPORT CLEANED DATA AS CSV\n",
    "\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/Users/svitlanakovalivska/onboarding_weebet/_onboarding_data-1/daily_tasks/day_4'\n",
    "csv_filename = 'cleaned_sat_results.csv'\n",
    "csv_path = os.path.join(output_dir, csv_filename)\n",
    "\n",
    "\n",
    "try:\n",
    "    # Export cleaned data to CSV\n",
    "    df_cleaned.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"SUCCESS: Cleaned data exported to CSV!\")\n",
    "    print(f\"File location: {csv_path}\")\n",
    "    print(f\"Exported {len(df_cleaned)} rows and {len(df_cleaned.columns)} columns\")\n",
    "    \n",
    "    # Verify file was created\n",
    "    if os.path.exists(csv_path):\n",
    "        file_size = os.path.getsize(csv_path)\n",
    "        print(f\"File size: {file_size:,} bytes\")\n",
    "    else:\n",
    "        print(\"Warning: CSV file not found after export\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" ERROR exporting CSV: {str(e)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
