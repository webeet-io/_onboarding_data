{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07ebd23",
   "metadata": {},
   "source": [
    "# Day 4: SAT Results Cleaning and Database Integration\n",
    "\n",
    "## ðŸ§  Task Summary\n",
    "\n",
    "The objective is to evaluate, clean, and integrate the `sat-results.csv` dataset into an existing PostgreSQL database.\n",
    "\n",
    "**Our goals:**\n",
    "1.  **Explore** the raw dataset to identify its structure, data types, and any issues.\n",
    "2.  **Clean** the data by handling duplicates, invalid values (like 's'), outliers, and formatting.\n",
    "3.  **Normalize** headers and drop fields that are not useful for analysis.\n",
    "4.  **Save** the cleaned data to `cleaned_sat_results.csv`.\n",
    "5.  **Append** this clean data to our PostgreSQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b26e3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e02d54",
   "metadata": {},
   "source": [
    "## 1. Exploration: Initial Load and Inspection\n",
    "\n",
    "First, we'll load the raw `sat-results.csv` and use `.info()` and `.head()` to get our first look at the data. This will help us spot any immediate problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc3cbe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame .info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493 entries, 0 to 492\n",
      "Data columns (total 11 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   DBN                              493 non-null    object \n",
      " 1   SCHOOL NAME                      493 non-null    object \n",
      " 2   Num of SAT Test Takers           493 non-null    object \n",
      " 3   SAT Critical Reading Avg. Score  493 non-null    object \n",
      " 4   SAT Math Avg. Score              493 non-null    object \n",
      " 5   SAT Writing Avg. Score           493 non-null    object \n",
      " 6   SAT Critical Readng Avg. Score   493 non-null    object \n",
      " 7   internal_school_id               493 non-null    int64  \n",
      " 8   contact_extension                388 non-null    object \n",
      " 9   pct_students_tested              376 non-null    object \n",
      " 10  academic_tier_rating             402 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 42.5+ KB\n",
      "\n",
      "--- DataFrame .head() ---\n",
      "      DBN                                    SCHOOL NAME  \\\n",
      "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
      "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                      7                             414                 401   \n",
      "4                     44                             390                 433   \n",
      "\n",
      "  SAT Writing Avg. Score SAT Critical Readng Avg. Score  internal_school_id  \\\n",
      "0                    363                            355              218160   \n",
      "1                    366                            383              268547   \n",
      "2                    370                            377              236446   \n",
      "3                    359                            414              427826   \n",
      "4                    384                            390              672714   \n",
      "\n",
      "  contact_extension pct_students_tested  academic_tier_rating  \n",
      "0              x345                 78%                   2.0  \n",
      "1              x234                 NaN                   3.0  \n",
      "2              x123                 NaN                   3.0  \n",
      "3              x123                 92%                   4.0  \n",
      "4              x123                 92%                   2.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('sat-results.csv')\n",
    "\n",
    "print(\"--- DataFrame .info() ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- DataFrame .head() ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8de867",
   "metadata": {},
   "source": [
    "## 2. Findings: Initial Assessment\n",
    "\n",
    "The initial inspection reveals several key issues:\n",
    "\n",
    "* **Bad Headers:** Column names have spaces and inconsistent capitalization (e.g., `SCHOOL NAME`).\n",
    "\n",
    "* **Wrong Data Types:** All SAT score columns (`Num of SAT Test Takers`, `SAT Critical Reading Avg. Score`, etc.) are `object` (text) type. They must be numeric.\n",
    "\n",
    "* **Redundancy:** We have both `SAT Critical Reading Avg. Score` and `SAT Critical Readng Avg. Score`. We need to check if they are identical.\n",
    "\n",
    "* **Inconsistent Formatting:** `pct_students_tested` is an `object` with '%' signs.\n",
    "\n",
    "* **Missing Data:** Several columns show a non-null count less than the total, indicating missing values.\n",
    "\n",
    "## 3. Cleaning (Step 1): Normalize Headers\n",
    "\n",
    "Let's fix the column names first. We'll convert them to lowercase `snake_case` for consistency and to make them database-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2536612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Columns ---\n",
      "Index(['DBN', 'SCHOOL NAME', 'Num of SAT Test Takers',\n",
      "       'SAT Critical Reading Avg. Score', 'SAT Math Avg. Score',\n",
      "       'SAT Writing Avg. Score', 'SAT Critical Readng Avg. Score',\n",
      "       'internal_school_id', 'contact_extension', 'pct_students_tested',\n",
      "       'academic_tier_rating'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Cleaned Columns ---\n",
      "Index(['dbn', 'school_name', 'num_of_sat_test_takers',\n",
      "       'sat_critical_reading_avg_score', 'sat_math_avg_score',\n",
      "       'sat_writing_avg_score', 'sat_critical_readng_avg_score',\n",
      "       'internal_school_id', 'contact_extension', 'pct_students_tested',\n",
      "       'academic_tier_rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Original Columns ---\")\n",
    "print(df.columns)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "df.columns = df.columns.str.replace(r'[^a-z0-9_]', '', regex=True)\n",
    "\n",
    "print(\"\\n--- Cleaned Columns ---\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7de592",
   "metadata": {},
   "source": [
    "## 4. Cleaning (Step 2): Handle Duplicates\n",
    "\n",
    "We need to ensure each school is represented only once. We'll check for complete row duplicates and then for duplicates on the `dbn` (District Borough Number) column, which should be our primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccbc4ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 complete row duplicates.\n",
      "\n",
      "Shape after dropping all duplicates: (478, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check for full-row duplicates\n",
    "df.duplicated().sum()\n",
    "print(f\"Found {full_duplicates} complete row duplicates.\")\n",
    "\n",
    "# Drop all duplicates, keeping the first instance\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"\\nShape after dropping all duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac7fc8",
   "metadata": {},
   "source": [
    "## 5. Cleaning (Step 3): Investigate and Handle Invalid Data\n",
    "\n",
    "The SAT score columns are text. This is usually because of a non-numeric placeholder. Let's find it. We'll also check the redundant \"readng\" column before dropping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa2ec7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the 'Reading' and 'Readng' columns identical? True\n",
      "\n",
      "--- Value counts for 'num_of_sat_test_takers' ---\n",
      "num_of_sat_test_takers\n",
      "s     57\n",
      "54    10\n",
      "9      8\n",
      "72     8\n",
      "48     8\n",
      "29     7\n",
      "61     7\n",
      "52     7\n",
      "49     7\n",
      "69     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check if the typo column is identical to the correct one\n",
    "are_identical = (df['sat_critical_reading_avg_score'] == df['sat_critical_readng_avg_score']).all()\n",
    "print(f\"Are the 'Reading' and 'Readng' columns identical? {are_identical}\")\n",
    "\n",
    "# Drop the typo column\n",
    "df.drop(columns='sat_critical_readng_avg_score', inplace=True)\n",
    "\n",
    "# Now, let's find the non-numeric value in the score columns\n",
    "print(\"\\n--- Value counts for 'num_of_sat_test_takers' ---\")\n",
    "print(df['num_of_sat_test_takers'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31b008",
   "metadata": {},
   "source": [
    "### Finding: The 's' Value\n",
    "\n",
    "The value `'s'` is present in many of the score columns, likely for \"Suppressed\" or \"Skipped\". These rows are unusable for score analysis. We will **remove all rows** where `num_of_sat_test_takers` is `'s'`.\n",
    "\n",
    "We'll also create a new `df_cleaned` DataFrame to protect our original `df` from here on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87c9d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape after deduplication: (478, 10)\n",
      "New shape after dropping 's' rows: (421, 10)\n"
     ]
    }
   ],
   "source": [
    "#Create a new DataFrame and remove the 's' rows\n",
    "df_cleaned = df[df['num_of_sat_test_takers'] != 's'].copy()\n",
    "\n",
    "print(f\"Original shape after deduplication: {df.shape}\")\n",
    "print(f\"New shape after dropping 's' rows: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825f6e9",
   "metadata": {},
   "source": [
    "## 6. Cleaning (Step 4): Convert Data Types\n",
    "\n",
    "Now that the `'s'` values are gone, we can safely convert all the score columns to numeric. We'll use `errors='coerce'` to turn any other unexpected text into `NaN` (Not a Number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e5b85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Info After Numeric Conversion ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 421 entries, 0 to 477\n",
      "Data columns (total 10 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   dbn                             421 non-null    object \n",
      " 1   school_name                     421 non-null    object \n",
      " 2   num_of_sat_test_takers          421 non-null    int64  \n",
      " 3   sat_critical_reading_avg_score  421 non-null    int64  \n",
      " 4   sat_math_avg_score              421 non-null    int64  \n",
      " 5   sat_writing_avg_score           421 non-null    int64  \n",
      " 6   internal_school_id              421 non-null    int64  \n",
      " 7   contact_extension               334 non-null    object \n",
      " 8   pct_students_tested             317 non-null    object \n",
      " 9   academic_tier_rating            352 non-null    float64\n",
      "dtypes: float64(1), int64(5), object(4)\n",
      "memory usage: 36.2+ KB\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = [\n",
    "    'num_of_sat_test_takers',\n",
    "    'sat_critical_reading_avg_score',\n",
    "    'sat_math_avg_score',\n",
    "    'sat_writing_avg_score'\n",
    "]\n",
    "\n",
    "# Apply pd.to_numeric to all columns in the list\n",
    "df_cleaned[numeric_columns] = df_cleaned[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(\"--- Info After Numeric Conversion ---\")\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13db51f",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# %% [markdown]\n",
    "# ## 7. Cleaning (Step 5): Handle Outliers (200-800)\n",
    "#\n",
    "# The SAT scores are now numeric, but they must be within the valid 200-800 range. We'll find any rows with scores outside this range and remove them, as they are data entry errors.\n",
    "\n",
    "# ==============================================================================\n",
    "# %% [code]\n",
    "# This query finds all rows that have an *invalid* score in *any* of the 3 sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f37a7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 rows with out-of-range SAT scores.\n",
      "\n",
      "Shape after dropping outliers: (416, 10)\n"
     ]
    }
   ],
   "source": [
    "outliers = df_cleaned.query(\n",
    "    'not (200 <= sat_critical_reading_avg_score <= 800) or '\n",
    "    'not (200 <= sat_math_avg_score <= 800) or '\n",
    "    'not (200 <= sat_writing_avg_score <= 800)'\n",
    ")\n",
    "\n",
    "print(f\"Found {len(outliers)} rows with out-of-range SAT scores.\")\n",
    "if not outliers.empty:\n",
    "    print(outliers[numeric_columns])\n",
    "\n",
    "# We'll use an inverse query to *keep* only the rows where all scores are valid\n",
    "df_cleaned = df_cleaned.query(\n",
    "    '(200 <= sat_critical_reading_avg_score <= 800) and '\n",
    "    '(200 <= sat_math_avg_score <= 800) and '\n",
    "    '(200 <= sat_writing_avg_score <= 800)'\n",
    ")\n",
    "\n",
    "print(f\"\\nShape after dropping outliers: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f80ca",
   "metadata": {},
   "source": [
    "## 8. Cleaning (Step 6): Format `pct_students_tested`\n",
    "\n",
    "This column is text (e.g., \"85%\"). We'll convert it to a numeric float (0.85).\n",
    "\n",
    "As per our strategy, we will **not** drop rows where this value is missing. We will convert existing values and leave the missing ones as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1354c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'pct_students_tested' unique values (before) ---\n",
      "pct_students_tested\n",
      "78%    111\n",
      "85%    105\n",
      "NaN    103\n",
      "92%     97\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- 'pct_students_tested' unique values (after) ---\n",
      "pct_students_tested\n",
      "0.78    111\n",
      "0.85    105\n",
      "NaN     103\n",
      "0.92     97\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 'pct_students_tested' unique values (before) ---\")\n",
    "print(df_cleaned['pct_students_tested'].value_counts(dropna=False).head())\n",
    "\n",
    "# 1. Replace '%' with nothing\n",
    "# 2. Convert to numeric, coercing errors (like 'N/A') to NaN\n",
    "# 3. Divide by 100 to get a float (e.g., 85 -> 0.85)\n",
    "df_cleaned['pct_students_tested'] = pd.to_numeric(\n",
    "    df_cleaned['pct_students_tested'].str.replace('%', '', regex=False),\n",
    "    errors='coerce'\n",
    ") / 100.0\n",
    "\n",
    "print(\"\\n--- 'pct_students_tested' unique values (after) ---\")\n",
    "print(df_cleaned['pct_students_tested'].value_counts(dropna=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4ec1454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 416 entries, 0 to 477\n",
      "Data columns (total 10 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   dbn                             416 non-null    object \n",
      " 1   school_name                     416 non-null    object \n",
      " 2   num_of_sat_test_takers          416 non-null    int64  \n",
      " 3   sat_critical_reading_avg_score  416 non-null    int64  \n",
      " 4   sat_math_avg_score              416 non-null    int64  \n",
      " 5   sat_writing_avg_score           416 non-null    int64  \n",
      " 6   internal_school_id              416 non-null    int64  \n",
      " 7   contact_extension               331 non-null    object \n",
      " 8   pct_students_tested             313 non-null    float64\n",
      " 9   academic_tier_rating            349 non-null    float64\n",
      "dtypes: float64(2), int64(5), object(3)\n",
      "memory usage: 35.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d71c4c",
   "metadata": {},
   "source": [
    "#### 9. Cleaning (Step 7): Final Column Selection\n",
    "\n",
    " Finally, we'll drop columns that are purely synthetic or internal (`internal_school_id`, `contact_extension`) and are not needed for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "032d3496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 416 entries, 0 to 477\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   dbn                             416 non-null    object \n",
      " 1   school_name                     416 non-null    object \n",
      " 2   num_of_sat_test_takers          416 non-null    int64  \n",
      " 3   sat_critical_reading_avg_score  416 non-null    int64  \n",
      " 4   sat_math_avg_score              416 non-null    int64  \n",
      " 5   sat_writing_avg_score           416 non-null    int64  \n",
      " 6   pct_students_tested             313 non-null    float64\n",
      " 7   academic_tier_rating            349 non-null    float64\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 29.2+ KB\n",
      "\n",
      "--- Final DataFrame Head ---\n",
      "      dbn                                    school_name  \\\n",
      "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
      "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
      "\n",
      "   num_of_sat_test_takers  sat_critical_reading_avg_score  sat_math_avg_score  \\\n",
      "0                      29                             355                 404   \n",
      "1                      91                             383                 423   \n",
      "2                      70                             377                 402   \n",
      "3                       7                             414                 401   \n",
      "4                      44                             390                 433   \n",
      "\n",
      "   sat_writing_avg_score  pct_students_tested  academic_tier_rating  \n",
      "0                    363                 0.78                   2.0  \n",
      "1                    366                  NaN                   3.0  \n",
      "2                    370                  NaN                   3.0  \n",
      "3                    359                 0.92                   4.0  \n",
      "4                    384                 0.92                   2.0  \n"
     ]
    }
   ],
   "source": [
    "df_final = df_cleaned.drop(columns=['internal_school_id', 'contact_extension'])\n",
    "\n",
    "print(\"--- Final DataFrame Info ---\")\n",
    "df_final.info()\n",
    "\n",
    "print(\"\\n--- Final DataFrame Head ---\")\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ef098",
   "metadata": {},
   "source": [
    "## 10. Save Cleaned File\n",
    "\n",
    "As required by the task, we'll save this cleaned DataFrame to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f5dac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to 'cleaned_sat_results.csv'\n"
     ]
    }
   ],
   "source": [
    "df_final.to_csv('cleaned_sat_results.csv', index=False)\n",
    "print(\"Successfully saved to 'cleaned_sat_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9c0a18",
   "metadata": {},
   "source": [
    "## 10. Create table on Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fd58066",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"ep-falling-glitter-a5m0j5gk-pooler.us-east-2.aws.neon.tech\"\n",
    "port = \"5432\"\n",
    "database = \"neondb\"\n",
    "user = \"neondb_owner\"\n",
    "password = \"a9Am7Yy5r9_T7h4OF2GN\"\n",
    "\n",
    "# Create a connection engine\n",
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4728e4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.to_sql(\n",
    "    name='michael_sat_results',       \n",
    "    con=engine,     \n",
    "    schema='nyc_schools',\n",
    "    if_exists='replace',    \n",
    "    index=False            \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
