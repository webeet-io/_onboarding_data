{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3931706-7133-49e5-8a61-294e920b4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Use psycopg2 or sqlalchemy to connect\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# connect to your database\n",
    "# example connection string → replace with your real credentials: (i had an value error before)\n",
    "\n",
    "# engine = create_engine('postgresql://postgres:myrealpassword@localhost:5432/postgres')\n",
    "# had to put this into comment because it really caused problems with unicode not printing the csv\n",
    "\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# ok visulacode had some utf-8 unicode isssues (thanks ai wouldn't have known how to approach this) let's see if it rolls now\n",
    "\n",
    "# load csv\n",
    "# with workaround \n",
    "\n",
    "with open('C:/Users/Maxdesk/Documents/GitHub/_onboarding_data/daily_tasks/day_4/day_4_datasets/sat-results.csv', mode='r', encoding='cp1252', errors='replace') as f:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "\n",
    "\n",
    "# lowercase column names\n",
    "df.columns = df.columns.str.lower().str.strip().str.replace('.', '').str.replace(' ', '_')\n",
    "\n",
    "# problems key error when ._ occured so i decided to replace dots with _ it follows a structure and keeps it simple\n",
    "# show columns and first rows\n",
    "\n",
    "print(df.columns.tolist())\n",
    "df.head()\n",
    "\n",
    "# replace 's' with NaN(not a number) in score columns so it will show later as null which is fine \n",
    "# because putting 0 would falsely return the score and maybe chances could be that we get a reported score later\n",
    "\n",
    "score_columns = [\n",
    "    'sat_critical_reading_avg_score',\n",
    "    'sat_math_avg_score',\n",
    "    'sat_writing_avg_score'\n",
    "]\n",
    "\n",
    "for col in score_columns:\n",
    "    df[col] = pd.to_numeric(df[col].replace('s', pd.NA), errors='coerce')\n",
    "\n",
    "# replace those 's' with nan in num of sat test takers\n",
    "\n",
    "df['num_of_sat_test_takers'] = pd.to_numeric(df['num_of_sat_test_takers'].replace('s', pd.NA), errors='coerce')\n",
    "\n",
    "# ok by now i first cleaned the structure and then cleaned  invalid sat scores so checkpoint 1 and 2\n",
    "# next step i will drop unrelated fields (mhm school name can be argued but let's keep it)\n",
    "df = df.drop(columns=[\n",
    "    'contact_extension',\n",
    "    'academic_tier_rating',\n",
    "    'school_name',\n",
    "    'internal_school_id',\n",
    "    'sat_critical_readng_avg_score'\n",
    "])\n",
    "# also i learned in pandas when NaN == NaN → False because i wanted to compare the data of the duplicates\n",
    "#i looked over it and they seem the same i safely dropped the onw with typo\n",
    "# check data types\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "# since we were hinted about inconsistent formatting (eg85%) pct students tested appears as an object/string\n",
    "# so it won't be usable for future filters so i will change that to float\n",
    "# also the numeric value is enough , the header already described this col is % so the sign isn't needed and steals dataspace also looks incoherent\n",
    "\n",
    "df['pct_students_tested'] = df['pct_students_tested'].str.replace('%', '').astype(float)\n",
    "df['num_of_sat_test_takers'] = df['num_of_sat_test_takers'].astype('Int64')\n",
    "\n",
    "#i was unsure if i should force all int but then the nan wouldn't always work  so i will use float for most\n",
    "# not for sat test takers - these can never be fractional <na> here instead NaN is a worthy workaround imo\n",
    "# well i don't know anything about sat scores but google helped  with each section (Evidence-Based Reading and Writing and Math) \n",
    "# scored on a 200-800 scale according to Yocket at least\n",
    "# define score columns\n",
    "\n",
    "score_columns = [\n",
    "    'sat_critical_reading_avg_score',\n",
    "    'sat_math_avg_score',\n",
    "    'sat_writing_avg_score'\n",
    "]\n",
    "\n",
    "# set invalid scores (< 200 or > 800) to NaN\n",
    "\n",
    "for col in score_columns:\n",
    "    df.loc[(df[col] < 200) | (df[col] > 800), col] = pd.NA\n",
    "\n",
    "# check missing values\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# show first rows again\n",
    "\n",
    "df.head()\n",
    "\n",
    "# force all string columns to valid UTF-8 BEFORE inserting\n",
    "\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype(str).str.encode('utf-8', errors='replace').str.decode('utf-8')\n",
    "# save cleaned dataframe to CSV\n",
    "\n",
    "df.to_csv('cleaned_sat_results.csv', index=False)\n",
    "\n",
    "print(\"Cleaned CSV saved as cleaned_sat_results.csv.\")\n",
    "\n",
    "# append data to sat_scores table\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# df.to_sql('sat_scores', engine, if_exists='append', index=False) \n",
    "# apparently it tried to use my realpw and that was why i always got some unicode error\n",
    "# now it seems fine after i commented out couple lines (even though i don't have my postgres pw - that was probably connected to some trashmail \n",
    "# i don't even know what happened there i even use english keyboard settings \n",
    "\n",
    "print(\"Data successfully appended to sat_scores table.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
